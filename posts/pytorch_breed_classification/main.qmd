---
title: "Image Classification with Pytorch Lightning"
image: "dc.jpg"
author: "Diegulio"
categories: [Pytorch, Lightning, Wandb, Timm, Gradio]
subtitle: "Classify images of pets using Pytorch Lightning"
date: "2023-10-23"
---


[![Open in Spaces](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-md-dark.svg)](https://huggingface.co/spaces/Diegulio/breed-classification)
[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/diegulio/pytorch-breed-classification)


# ‚ö°Ô∏è T√≥pico: Breed Classification with Pytorch Lightning

En este post, resolveremos un problema cl√°sico de Machine Learning: **Clasificaci√≥n**. Lo interesante, es que no ser√° un problema tabular, si no que ser√° un problema de **Computer Vision** üëÅÔ∏è. Esto quiere decir que utilizaremos modelos de Deep Learning para clasificar im√°genes dentro de un set de categorias (o clases) pre-definidas. Si bien es un problema cl√°sico, el hecho de que la entrada de nuestro modelo sean im√°genes hace todo el tema mucho m√°s motivante, y es un buen punto de partida para escalar y luego resolver problemas tales como: Object detection, Segmentation, Image generation, entre otros. 

::: {.callout-note icon=false}
## ‚ÑπÔ∏è
Este post busca ense√±ar la implementaci√≥n m√°s que los detalles te√≥ricos. Si bien la teor√≠a es muy importante, en este caso, al ser una implementaci√≥n m√°s avanzada, me centrar√© en ella.

:::


# üîé¬†Motivaci√≥n: Find your pet

Imaginemos tenemos una p√°gina web en donde las personas pueden subir carteles de sus mascotas perdidas, y a la vez carteles de sus mascotas encontradas. Una caracter√≠stica importante en tu p√°gina web ser√≠a tener un buen algoritmo de recomendaci√≥n que logre hacer match entre estas mascotas. Algo que podr√≠a ayudar, es poder identificar correctamente la raza de la mascota (a veces los usuarios no saben de que raza es su mascota).

De hecho, el modelo que elaboraremos aqu√≠ puede servir para m√°s que simplemente identificar la raza de la mascota. No pretendo profundizar en esto, pero en realidad nuestro modelo podr√° utilizarse para generar Embeddings, i.e formas de representar una imagen vectorialmente en una dimensi√≥n menor. Esto puede ser utilizado directamente en sistemas de recomendaci√≥n, recomendando aquellas mascotas encontradas que tengan embeddings cercanos a el embedding de la mascota que estamos buscando. Disclaimer: esto por s√≠ s√≥lo podr√≠a no ser un muy buen recomendador porque probablemente s√≥lo recomendar√° mascotas de la misma raza. Si no entendiste este p√°rrafo, no te preocupes, no es el tema principal de este post. A√∫n as√≠, te recomiendo estudiar sobre que son los Embeddings!

üß†¬†**Soluci√≥n: Crear un modelo de clasificaci√≥n de im√°genes para detectar si una imagen corresponde a: Alguna raza de perro, gato o ninguno.**

# üî®¬†Tool Path: Que utilizaremos

A continuaci√≥n les dejo las herramientas que utilizaremos en este post:

1. **Pytorch**:  es una biblioteca de c√≥digo abierto para el desarrollo de aplicaciones de aprendizaje profundo y la investigaci√≥n en inteligencia artificial.
2. **Pytorch Lightning**: es una extensi√≥n de PyTorch que simplifica y estandariza el proceso de entrenamiento y desarrollo de modelos de aprendizaje profundo en PyTorch, facilitando la creaci√≥n de c√≥digo limpio y modular. 
3. **Weight and Biases**: plataforma que permite realizar un seguimiento, visualizaci√≥n y colaboraci√≥n en proyectos de Machine Learning.
4. **Timm**: biblioteca que proporciona una amplia variedad de modelos de redes neuronales pre-entrenados para tareas de computer vision en PyTorch.
5. **Gradio**: facilita la creaci√≥n de interfaces de usuario interactivas para modelos de Machine Learning.

# üí≠¬†Concept Path: Que aprenderemos

A continuaci√≥n algunos de los conceptos que veremos: 

1. Convolutional Neural Networks
2. Transfer Learning
3. Data Augmentation
4. Early Stopping
5. Learning rate scheduling

La mayor parte de estos conceptos los explicar√© en un bajo nivel de detalle, creo que existen m√∫ltiples recursos en internet con un muy buen nivel de detalle y explicabilidad de estos conceptos. Pero como siempre, si sientes que te gustar√≠a profundizar en algo, charlemos!

# ‚ôüÔ∏è¬†Estrategia: Como abordamos

Al ser un cl√°sico problema de ML, procederemos como se acostumbra:

1. Recolectar datos: Buscar nuestras im√°genes y sus respectivas etiquetas.
2. Definir una linea base: Un modelo f√°cil y r√°pido.
3. Aplicaremos otros modelos (usualmente m√°s complejos): Creamos un benchmark para nuestro caso de uso.
4. Iteramos: Iteramos aplicando distintas t√©cnicas, buscando mejorar nuestros resultados.
5. Deploy: Desplegamos nuestra aplicaci√≥n para que sea utilizada por el p√∫blico.

Claramente existen otros pasos importantes, pero que no vienen al caso. Ej: Estudio de negocio, de factibilidad, de datos, etc.

# üß†¬†Prototyping

Recordar que en esta ocasi√≥n utilizaremos **Pytorch Lightning**. Esta herramienta es un wrapper de Pytorch, que nos permite reducir la duplicidad de c√≥digo y aumentar la modularidad. En otras palabras, es m√°s f√°cil crear las rutinas de entrenamiento. 

![En la izquierda, podemos ver la rutina de entrenamiento utilizando Pytorch puro. A la derecha podemos ver como es reducida al utilizar Pytorch Lightning, sacrificando s√≥lo una pizca de flexibilidad.<br>
  Fuente: [https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09](https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09)](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled.png)




En resumen, Pytorch Lightning hace por nosotros un mont√≥n de cosas como: el loop de epochs, utilizar gpu o no, calcular o no gradientes, computar m√©tricas a trav√©s de cada paso, etc. 

A√∫n as√≠, lo que necesitamos es muy similar a lo que se necesita en Pytorch puro. Esto es:

1. **Una clase Dataset**: clase que facilita el acceso a la data. En este caso, a las im√°genes.
2. **Un Dataloader**: La forma en como los datos son cargados al momento de entrenar.
3. **Una clase Modelo**: Ac√° indicamos de que se compone nuestro modelo, las capas que utiliza, el optimizador,  la predicci√≥n, etc.
4. Todo lo anterior es utilizado en la clase **Trainer** de Pytorch Lightning. La cual se preocupa de hacer toda la rutina de entrenamiento por nosotros! 

A grandes rasgos, todo el proceso deber√≠a ser algo como:

```python
import torch

# 1. Dataset
class MyDataset:
	"""
	Como consulto mi dataset?
	"""
	pass

dataset = MyDataset()

# 2. Dataloader -> como cargo mis datos
dataloader = DataLoader(dataset)

# 3. Modelo
class MyModel:
  """
	Cual es la arquitectura de mi modelo?
	C√≥mo pasan las imagenes atrav√©s de mi modelo?
	"""
	pass

modelo = Mymodel()

# 4. Trainer

trainer = Trainer() # Algunas configuraciones de entrenamiento

# 5. Fit
trainer.fit(modelo, train_dataloader, val_dataloader) # Entrenamiento

# 6. Evaluate
trainer.evaluate(modelo, test_dataloader)
```

## Config

Normalmente, se utiliza un archivo, clase, etc. para definir la configuraci√≥n general de nuestra aplicaci√≥n. Por ejemplo: el nombre del modelo que utilizaremos, la ruta a la imagen, la ruta a el archivo de etiquetas, etc.

Por ahora, nuestra clase config ser√°:

```python
class CFG:
  IMG_PATH = 'PATH/TO/IMAGES' # Ruta a imagenes
  LABEL_PATH = '/PATH/TO/labels.csv' # Ruta a archivo de etiquetas

  # Data
  TEST_SIZE = 0.2 # Tama√±o del conjunto de test
  VAL_SIZE = 0.1 #¬†Tama√±o del conjunto de validaci√≥n

```

A medida avancemos, iremos agregando cada vez m√°s variables.

## 1. Dataset

Al ser un problema supervisado, necesitaremos im√°genes y sus respectivas etiquetas. Un dato freak, es que este proyecto ya lo habia resuelto hace unos a√±os utilizando Tensorflow. En esa ocasi√≥n me tom√© el tiempo de recolectar datos de distintas fuentes para construir el dataset final, para mayor informaci√≥n de como lo hice (no es tan importante), leer [aqu√≠](https://github.com/diegulio/Breed_Recognition-to-Buscomiperro/blob/main/ProjectLifeDiary.md). 

TLDR: extraje una base de datos de Stanford de razas de perro, un dataset de Kaggle de gatos, y descargu√© manualmente algunas im√°genes pseudo-aleatorias (otros animales, personas, cosas, paisajes). Juntando todo esto cre√© un dataset con las siguientes clases:

- 120 razas de perro
- Gato
- No detectado

 Lo que tenemos, es una carpeta con cientos de im√°genes. Adem√°s, tenemos un archivo .csv que nos indica la clase seg√∫n el nombre de la imagen. Esto nos ser√° util para la construcci√≥n de la clase personalizada Dataset en Pytorch:

![sample archivo labels.csv](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%201.png)


Todas las im√°genes son jpg, por lo que la extensi√≥n la agrego en el c√≥digo. Algo importante a mencionar, es que este dataset est√° balanceado (o almenos, no preocupantemente imbalanceado). Por lo que tenemos una cantidad decente de im√°genes para cada clase.

### Split

Como todo problema de ML, necesitaremos dividir nuestros datos en entrenamiento, validaci√≥n y testeo. Para esto, s√≥lo necesitaremos dividir el dataframe de el archivo de labels, ya que este mismo ser√° utilizando en el siguiente paso (Pytorch Dataset). 

```python
from sklearn.model_selection import train_test_split

# Leemos el archivo de anotaciones/etiquetas
labels = pd.read_csv(CFG.LABEL_PATH)

X = labels.id #¬†Data (paths)
y = labels.breed # Target

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=CFG.TEST_SIZE, random_state=13, shuffle = True, stratify = y)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=CFG.VAL_SIZE, random_state=13, shuffle = True, stratify = y_train)

# Dejamos todo en un df para cada conjunto
train_labels = pd.concat([X_train, y_train], axis = 1).reset_index(drop = True)
val_labels = pd.concat([X_val, y_val], axis = 1).reset_index(drop = True)
test_labels = pd.concat([X_test, y_test], axis = 1).reset_index(drop = True)

```

### Pytorch Dataset

Code time üë®üèæ‚Äçüíª¬†! 

Para crear una clase Dataset personalizada en Pytorch, se necesitan 3 m√©todos fundamentales:

1. **`__init__`**: La funci√≥n **`__init__`** se ejecuta una vez al crear una instancia del objeto Dataset. Inicializamos el directorio que contiene las im√°genes, el archivo de anotaciones y transformaciones.
2. **`__len__`**: La funci√≥n **`__len__`** devuelve el n√∫mero de muestras en nuestro conjunto de datos.
3. **`__getitem__`**: La funci√≥n **`__getitem__`** carga y devuelve una muestra del conjunto de datos en el √≠ndice *idx* dado. 

- Hagamos esto de forma iterativa, en un paso 0 deberiamos tener algo como:

```python
from torch.utils.data import Dataset

# Clase Dataset
class PetDataSet(Dataset):

  def __init__(self):
    pass

  def __len__(self):
    pass

  def __getitem__(self, idx):
    pass
```

- Ahora, comenzaremos por el m√©todo **`__init__`**, ac√° es donde se inicializa la instancia. Es en donde buscaremos definir los atributos a usar en los siguientes m√©todos (`__len__` y `__getitem__`). B√°sicamente, lo que necesitaremos son: **las im√°genes** (o la ruta a donde est√°n), y el **archivo** **labels** que nos dice la clase de cada imagen seg√∫n su nombre.

Adem√°s ver√°s un par√°metro llamado **transforms**. Por ahora, imagina que esta es una funci√≥n que le cambia el tama√±o a la imagen. Esto es importante ya que no podemos alimentar al modelo con im√°genes de distintos tama√±os.  M√°s adelante, veremos como esta funci√≥n puede hacer mucho m√°s que s√≥lo cambiar el tama√±o a las im√°genes. 

```python
from torch.utils.data import Dataset

class PetDataSet(Dataset):

  def __init__(self, config, labels, transform):
    self.labels = labels # DataFrame de etiquetas
    self.dir = config.IMG_PATH #¬†Path de imagenes
    self.config = config # Clase configuraciones**

  def __len__(self):
    pass

  def __getitem__(self, idx):
    pass
```

- `__len__`: Ahora debemos calcular el largo de nuestro dataset. Esto es directo, ya que ser√° igual a la cantidad de filas de nuestro DataFrame labels.

```python
from torch.utils.data import Dataset

class PetDataSet(Dataset):

  def __init__(self, config, labels, transform):
    self.labels = labels # DataFrame de etiquetas
    self.dir = config.IMG_PATH #¬†Path de imagenes
    self.config = config # Clase configuraciones

  def __len__(self):
    return len(self.labels) # largo de dataset**

  def __getitem__(self, idx):
    pass
```

- Finalmente, el m√©todo `__getitem__`, el m√°s complejo. Debemos asumir que la entrada ser√° un indice, y necesitaremos que devuelva la imagen correspondiente (en pixeles), y su clase.

```python
from torch.utils.data import Dataset

class PetDataSet(Dataset):

  def __init__(self, config, labels, transform):
    self.labels = labels # DataFrame de etiquetas
    self.dir = config.IMG_PATH #¬†Path a imagenes
    self.config = config # Configuraciones
    self.transform = transform # Transformaciones

  def __len__(self):
    return len(self.labels)  # largo de dataset

  def __getitem__(self, idx):
    breed = self.labels.iloc[idx, 1] # Etiqueta desde dataframe
    img_path = self.labels.iloc[idx, 0] #¬†Nombre imagen desde dataframe
    full_path = os.path.join(self.dir, f'{img_path}.jpg') # Path completo a imagen
    image = read_image(full_path)/255 #¬†Se lee y normaliza la imagen 
    img = self.transform(image)  # Funci√≥n que cambia el tama√±o de la imagen
    return img, breed #¬†Se retorna la imagen y la clase**
```

::: {.callout-note icon=false}
## üö®
ALTO AHI! Si nos damos cuenta, tomamos las im√°genes y las convertimos a pixeles (n√∫meros). Esto es super l√≥gico, ya que los modelos **s√≥lo** leen n√∫meros! pero ¬øpor qu√© estamos retornando *breed*, si *breed* es una palabra?  
La verdad es que esto es un error, por lo que debemos arregarlo. Para eso, le asignaremos un numero entero (√≠ndice) a cada clase, y as√≠ el modelo podr√° trabajar tranquilo.

:::

Para esto creamos un diccionario que le asignar√° un n√∫mero entero (√≠ndice) a cada clase i.g dalmata ‚Üí 0. Adem√°s crearemos un diccionario que seg√∫n un n√∫mero entero, nos indique a que clase pertenece i.g 0 ‚Üí dalmata. Todo esto lo haremos en nuestra clase de configuraci√≥n:

```python
class CFG:
  IMG_PATH = 'PATH/TO/IMAGES' # Ruta a imagenes
  LABEL_PATH = '/PATH/TO/labels.csv' # Ruta a archivo de etiquetas

  # Data
  TEST_SIZE = 0.2
  VAL_SIZE = 0.1

  labels = pd.read_csv(LABEL_PATH) # leemos archivo de etiquetas
  idx_to_class = dict(enumerate(labels.breed.unique())) # id -> clase
  class_to_idx = {c:i for i,c in idx_to_class.items()} # clase -> id**
```

Ahora nuestra clase dataset quedar√° como:

```python
from torch.utils.data import Dataset

class PetDataSet(Dataset):
  def __init__(self, config, labels, transform):
    self.labels = labels # DataFrame de etiquetas
    self.dir = config.IMG_PATH #¬†Path de imagenes
    self.config = config # Configuraciones
    self.transform = transform # Transformaciones

  def __len__(self):
    return len(self.labels)

  def __getitem__(self, idx):
    breed = self.labels.iloc[idx, 1] # Etiqueta desde dataframe
    class_id = self.config.class_to_idx[breed]** # Convertimos clase a n√∫mero
    img_path = self.labels.iloc[idx, 0] #¬†Nombre imagen
    full_path = os.path.join(self.dir, f'{img_path}.jpg') # Path completo a imagen
    image = read_image(full_path)/255 # Normalizaci√≥n de la imagen
    img = self.transform(image)  # Funci√≥n que cambia el tama√±o de la imagen
    return img, class_id # Se retorna la imagen y el indice de la clase**
```

Vo√≠la! Hemos terminado nuestra clase Dataset, s√≥lo falta inicializarla.

```python
train_dataset = PetDataSet(config = CFG, labels = train_labels, transform = train_transform)
val_dataset = PetDataSet(config = CFG, labels = val_labels, transform = test_transform)
test_dataset = PetDataSet(config = CFG, labels = test_labels, transform = test_transform)
```

Ahora podemos consultar nuestra data, por ejemplo:

```python
len(train_dataset) # -> nos entregar√° el largo del dataset

pixels, class_id = train_dataset[0] # nos entregara la informaci√≥n del elemento 0
```

## 2. DataLoader

El modelo no ir√° consultando nuestra data uno por uno, ni toda a la vez. En realidad, nosotros le iremos entregando nuestras im√°genes en **batches**. Gracias a esto, nuestro modelo es m√°s eficiente y evitamos cualquier problemas de memoria (imagina cargar un mill√≥n de im√°genes a la vez en nuestra memoria RAM üí•). 

```python
from torch.utils.data import DataLoader

train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers = 1)
val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers = 1)
test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers = 1)
```

Existen otras cosas que los DataLoader pueden hacer, pero por ahora con esto basta.  Para mayor informaci√≥n visita la [documentaci√≥n](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).

## 3. Model

Para el modelo, utilizaremos una t√©cnica llamada Transfer Learning.

::: {.callout-note icon=false}
## ü§ñ 
Transfer learning (aprendizaje por transferencia) es una t√©cnica de aprendizaje autom√°tico en la que se aprovecha el conocimiento adquirido por un modelo entrenado en una tarea espec√≠fica y se aplica a una tarea relacionada. En lugar de entrenar un modelo desde cero, se toma un modelo pre-entrenado y se ajusta o se "transfiere el conocimiento" para adaptarse a una nueva tarea. Esto a menudo ahorra tiempo y recursos, y puede resultar en un rendimiento mejorado en la nueva tarea, especialmente cuando los datos de entrenamiento son limitados.

:::

Existe una gran variedad de modelos de Computer Vision, los m√°s conocidos son las redes convolucionales. Por bastante tiempo esta t√©cnica ha estado en el estado del arte de computer vision. Te recomiendo leer m√°s [ac√°](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939). 

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%202.png)

En este caso, utilizaremos como base alguna de las arquitecturas m√°s conocidas pre-entrenadas. Luego, cambiaremos la parte de Clasificaci√≥n, para que prediga entre las clases de nuestro propio caso de uso y entrenaremos en base a eso.

Debemos recordar que cuando uno entrena un modelo, lo que hace es ajustar ciertos pesos(par√°metros) de forma que se reduzca la funci√≥n de p√©rdida. En estas arquitecturas, existen millones de pesos a lo largo de la red. Debido a que el modelo est√° pre-entrenado, estos pesos ya han logrado capturar ciertos patrones, lo que facilitar√° la convergencia de nuestro modelo en el caso de uso que queremos: detectar razas de mascotas.

Intentar ajustar todos los pesos har√° que nuestro modelo demore en converger y requiramos m√°s recursos computacionales, adem√°s puede que no tengamos los mejores resultados. Una pr√°ctica com√∫n es **congelarü•∂** los pesos de la red pre-entrenada, y s√≥lo ajustar los pesos de la parte de clasificaci√≥n, y a veces algunas de las √∫ltimas capas. ¬ø Porque s√≥lo las √∫ltimas capas? Existen estudios que se√±alan que las √∫ltimas capas son aquellas que capturan los patrones m√°s espec√≠ficos/complejos de los casos de uso. Entonces si el modelo fue pre-entrenado en cebras, las √∫ltimas capas probablemente se fijar√°n en caracter√≠sticas espec√≠ficas o m√°s complejas de las cebras, mientras las primeras capas en caracter√≠sticas m√°s generales de los animales. Esto es muy conveniente, nos gustar√≠a conservar las caracter√≠sticas generales y ajustar aquellos pesos que detectan las caracter√≠sticas m√°s espec√≠ficas, para as√≠ detectar patrones complejos en nuestro propio caso de uso. 

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%203.png)

Para resumir, el procedimiento ser√° el siguiente:

1. Tomamos una arquitectura base (Backbone)
2. Sustituimos la secci√≥n de clasificaci√≥n por una propia.
3. Congelamos los par√°metros (pesos) de el modelo pre-entrenado.
4. Entrenamos con nuestra data.

![Arriba, el modelo pre-entrenado en el dataset ImageNet. Abajo el mismo modelo (par√°metros) aplicado a salud, utilizando un dataset m√©dico. Notar que la secci√≥n de Fully Connected Layers no es la misma, ya que la primera fue dise√±ada para predecir una gran variedad de clases, mientras que la segunda para predecir entre benigno o maligno (dos clases).
Fuente: [https://www.mdpi.com/1424-8220/23/2/570](https://www.mdpi.com/1424-8220/23/2/570)](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%204.png)


### TIMM (pyTorch Image Models)

Una primera pregunta ser√≠a ¬øQue modelo base utilizar? No hay una respuesta completamente te√≥rica, creo que la respuesta simple ser√≠a: **experimentar**.

Existe un sin-fin de modelos base pre-entrenados, nosotros probaremos algunos de los m√°s conocidos: **EfficientNet, VGG, Inception y Resnet.** Lo que haremos ser√° entrenar estos modelos y quedarnos con aqu√©l que nos entregue mejores resultados.

Para extraer los modelos pre-entrenados, utilizaremos **timm:** `timm` es una biblioteca de aprendizaje profundo creada por Ross Wightman y es una colecci√≥n de modelos, capas, utilidades, optimizadores, programadores, cargadores de datos, aumentos y tambi√©n scripts de entrenamiento/validaci√≥n de computer vision SOTA models con capacidad para reproducir resultados de entrenamiento de ImageNet.

B√°sicamente es un repositorio de modelos pre-entrenados. Existen varios, Pytorch y tensorflow tambi√©n tienen sus propios HUBs. 

Traer un modelo pre-entrenado en timm es muy simple. S√≥lo debemos:

```python
import timm
base_model = timm.create_model("model_name", pretrained = True, num_classes = len(CFG.idx_to_class))
```

Al entregarle el par√°metro `num_classes`. Timm autom√°ticamente reemplaza la capa final de clasificaci√≥n para que nos entregue predicciones acordes a nuestro caso de uso! 

A√∫n as√≠, para utilizar Pytorch Lightning debemos crear nuestra clase Model. 

Antes de comenzar a crear nuestra clase modelo, actualicemos nuestra clase configuraci√≥n con par√°metros relacionados a √©sta.

```python
class CFG:
  IMG_PATH = 'PATH/TO/IMAGES' # Ruta a imagenes
  LABEL_PATH = '/PATH/TO/labels.csv' # Ruta a archivo de etiquetas

  # Data
  TEST_SIZE = 0.2
  VAL_SIZE = 0.1

  labels = pd.read_csv(LABEL_PATH) # leemos archivo de etiquetas
  idx_to_class = dict(enumerate(labels.breed.unique())) # id -> clase
  class_to_idx = {c:i for i,c in idx_to_class.items()} # clase -> id

  # Model related
  LEARNING_RATE = 0.001
  MODEL = 'inception_v4' # timm name
  PRETRAINED = True
```

### Pytorch Lightning ‚ö°Ô∏è

Al igual que en Dataset, **Pytorch** requiere algunos m√©todos fundamentales en la creaci√≥n de la clase Model. Estos son:

- **`__init__()`:** M√©todo que define las capas y otros componentes de un modelo.
- **`forward()`¬†:** m√©todo donde se realiza el c√°lculo a trav√©s de la red. Tener en cuenta que podemos imprimir el modelo, o cualquiera de sus subm√≥dulos, para conocer su estructura.

A√∫n as√≠, **Pytorch Lightning** necesita unos m√©todos extras: 

- **`training_step()`**:  l√≥gica de entrenamiento.
- **`configure_optimizers()`:** definir optimizadores y/o programadores LR.

Existen un mont√≥n de otros m√©todos importantes y √∫tiles, los puedes ver [ac√°](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#training). 

- Comencemos con el paso 0:

```python
class PetRecognitionModel(**L.LightningModule**):

  def __init__(self):
    super().__init__()
    pass

  def forward(self, x):
    pass

  def training_step(self, batch, batch_idx):
    pass

  def configure_optimizers(self):
    pass
```

En el c√≥digo original, agregu√© otros m√©todos que utilic√©, pero que s√≥lo mostrar√© en este blog. Muchos de ellos eran para hacer la validaci√≥n, testeo, predicci√≥n y logging. 

- En cuanto al m√©todo **`__init__()`,** inicializaremos la configuraci√≥n, el modelo base y la m√©trica a utilizar:

```python
class PetRecognitionModel(L.LightningModule):

  def __init__(self, base_model, config):
    super().__init__()
    self.config = config
    self.num_classes = len(self.config.idx_to_class)
    self.metric = Accuracy(task="multiclass", num_classes=self.num_classes)
		
    self.pretrained_model = base_model

  def forward(self, x):
    pass

  def training_step(self, batch, batch_idx):
    pass

  def configure_optimizers(self):
    pass
```

- **`forward()`** el m√©todo forward es bastante sencillo, debemos definir como nuestro input pasar√° a trav√©s de nuestra arquitectura. Debido a que es sencilla, simplemente har√° un paso por el modelo base, resultando:

```python
class PetRecognitionModel(L.LightningModule):
  def __init__(self, base_model, config):
    super().__init__()
    self.config = config
    self.num_classes = len(self.config.idx_to_class)
    self.metric = Accuracy(task="multiclass", num_classes=self.num_classes)
		
    self.pretrained_model = base_model

  def forward(self, x):
    return self.pretrained_model(x)**

  def training_step(self, batch, batch_idx):
    pass

  def configure_optimizers(self):
    pass
```

- **`training_step()`** puede ser un poco m√°s complicado, la entrada de esta funci√≥n ser√° el batch de im√°genes y labels, y debemos retornar la funci√≥n de p√©rdida para ese batch.

```python
class PetRecognitionModel(L.LightningModule):
  def __init__(self, base_model, config):
    super().__init__()
    self.config = config
    self.num_classes = len(self.config.idx_to_class)
    self.metric = Accuracy(task="multiclass", num_classes=self.num_classes)
		
    self.pretrained_model = base_model

  def forward(self, x):
    return self.pretrained_model(x)

  def training_step(self, batch, batch_idx):
    x,y = batch # dividimos el batch en data y labels
    logits = self.forward(x) # la data pasa a trav√©s del modelo
    loss = F.cross_entropy(logits, y) # Calculamos la funci√≥n de p√©rdida
    self.log_dict({'train_loss': loss}) # Logueamos el resultado
    return loss #¬†retornamos la p√©rdida

  def configure_optimizers(self):
    pass
```

Por ahora, no te preocupes de la linea `self.log_dict({'train_loss': loss})`, m√°s adelante veremos para que es.

- **`configure_optimizers()`:** Finalmente debemos definir nuestro optimizador, el cu√°l ser√° bastante est√°ndar: utilizaremos *Adam* con alg√∫n *learning_rate* dado.

```python
from torch import optim

class PetRecognitionModel(L.LightningModule):
  def __init__(self, base_model, config):
    super().__init__()
    self.config = config
    self.num_classes = len(self.config.idx_to_class)
    self.metric = Accuracy(task="multiclass", num_classes=self.num_classes)
		
    self.pretrained_model = base_model

  def forward(self, x):
    return self.pretrained_model(x)

  def training_step(self, batch, batch_idx):
    x,y = batch # dividimos el batch en data y labels
    logits = self.forward(x) # la data pasa a trav√©s del modelo
    loss = F.cross_entropy(logits, y) # Calculamos la funci√≥n de p√©rdida
    self.log_dict({'train_loss': loss}) # Logueamos el resultado
    return loss #¬†retornamos la p√©rdida

  def configure_optimizers(self):
    optimizer = optim.Adam(self.parameters(), lr=self.config.LEARNING_RATE)
    return {'optimizer': optimizer}
```

Listo! ya tenemos nuestro modelo para entrenar. Si quieres ver la implementaci√≥n completa, te recomiendo visitar el c√≥digo en el repositorio de [github](https://github.com/diegulio/pytorch-breed-classification). A√∫n as√≠, ahora te mostrar√© el c√≥digo final luego de agregarle m√©todos adicionales:

```python
class PetRecognitionModel(L.LightningModule):
  def __init__(self, base_model, config):
    super().__init__()
    self.config = config
    self.num_classes = len(self.config.idx_to_class)
    metric = Accuracy(task="multiclass", num_classes=self.num_classes)
    self.train_acc = metric.clone()
    self.val_acc = metric.clone()
    self.test_acc = metric.clone()
    self.training_step_outputs = []
    self.validation_step_outputs = []
    self.test_step_outputs = []

    self.pretrained_model = base_model

  def forward(self, x):
    x = self.pretrained_model(x)
    return x

  def training_step(self, batch, batch_idx):
    x,y = batch
    logits = self.forward(x) # -> logits
    loss = F.cross_entropy(logits, y)
    self.log_dict({'train_loss': loss})
    self.training_step_outputs.append({'loss': loss, 'logits': logits, 'y':y})
    return loss

  def on_train_epoch_end(self):
    # Concat batches
    outputs = self.training_step_outputs
    logits = torch.cat([x['logits'] for x in outputs])
    y = torch.cat([x['y'] for x in outputs])
    self.train_acc(logits, y)
    self.log_dict({
        'train_acc': self.train_acc,
      },
      on_step = False,
      on_epoch = True,
      prog_bar = True)
    self.training_step_outputs.clear()

  def validation_step(self, batch, batch_idx):
    x,y = batch
    logits = self.forward(x)
    loss = F.cross_entropy(logits, y)
    self.log_dict({'val_loss': loss})
    self.validation_step_outputs.append({'loss': loss, 'logits': logits, 'y':y})
    return loss

  def on_validation_epoch_end(self):
    # Concat batches
    outputs = self.validation_step_outputs
    logits = torch.cat([x['logits'] for x in outputs])
    y = torch.cat([x['y'] for x in outputs])
    self.val_acc(logits, y)
    self.log_dict({
        'val_acc': self.val_acc,
      },
      on_step = False,
      on_epoch = True,
      prog_bar = True)
    self.validation_step_outputs.clear()

  def test_step(self, batch, batch_idx):
    x,y = batch
    logits = self.forward(x)
    loss = F.cross_entropy(logits, y)
    self.log_dict({'test_loss': loss})
    self.test_step_outputs.append({'loss': loss, 'logits': logits, 'y':y})
    return loss

  def on_test_epoch_end(self):
    # Concat batches
    outputs = self.test_step_outputs
    logits = torch.cat([x['logits'] for x in outputs])
    y = torch.cat([x['y'] for x in outputs])
    self.test_acc(logits, y)
    self.log_dict({
        'test_acc': self.test_acc,
      },
      on_step = False,
      on_epoch = True,
      prog_bar = True)
    self.test_step_outputs.clear()

  def predict_step(self, batch):
        x, y = batch
        return self.model(x, y)

  def configure_optimizers(self):
    optimizer = optim.Adam(self.parameters(), lr=self.config.LEARNING_RATE)
    lr_scheduler = ReduceLROnPlateau(optimizer, mode = 'min', patience = 3)
    lr_scheduler_dict = {
        "scheduler": lr_scheduler,
        "interval": "epoch",
         "monitor": "val_loss",
    }
    return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler_dict}
```

La mayor parte de los m√©todos adicionales fueron hechos para poder ir monitoreando las m√©tricas de el modelo, m√°s adelante veremos por qu√©. 

Finalmente, s√≥lo nos falta instanciar el modelo.

```python
model = PetRecognitionModel(base_model, config = CFG)
```

Ahora, una parte importante ser√° congelar aquellos par√°metros que no queremos entrenar. Para esto, congelaremos todos los par√°metros del modelo, y luego descongelaremos aquellos pertenecientes a las √∫ltimas capas:

```python
def freeze_pretrained_layers(model, model_name):
    '''Freeze all layers except the last layer(fc or classifier)'''
		#¬†Freeze All params
    for param in model.parameters():
            param.requires_grad = False

    # Unfreeze Classifier Parameters EfficientNET
    if model_name == 'efficientnet_b2':
      model.pretrained_model.classifier.weight.requires_grad = True
      model.pretrained_model.classifier.bias.requires_grad = True
    # Unfreeze Classifier Parameters VGG19
    elif model_name == 'vgg19_bn':
      model.pretrained_model.head.fc.weight.requires_grad = True
      model.pretrained_model.head.fc.bias.requires_grad = True
		# Unfreeze Classifier Parameters Inception
    elif model_name == 'inception_v4':
      model.pretrained_model.last_linear.weight.requires_grad = True
      model.pretrained_model.last_linear.bias.requires_grad = True
		# Unfreeze Classifier Parameters Resnet
    elif model_name == 'resnet50':
      model.pretrained_model.fc.weight.requires_grad = True
      model.pretrained_model.fc.bias.requires_grad = True
    else:
      raise Exception('Modelo no encontrado')
```

Puedes notar que los nombres de las capas varian seg√∫n el modelo. Ahora s√≥lo debemos aplicar la funci√≥n.

```python
freeze_pretrained_layers(model, model_name = CFG.MODEL)
```

## 4. Trainer

Alfin, ahora s√≥lo nos queda entrenar. Esto ser√° muy sencillo gracias al m√≥dulo **Trainer** de Pytorch Lightning, el cual se encargar√° de elaborar la rutina de entrenamiento en base a lo que definimos anteriormente. 

Primero, definimos Trainer junto con las configuraciones que deseemos:

- Actualizamos clase CFG

```python
class CFG:
  IMG_PATH = 'PATH/TO/IMAGES' # Ruta a imagenes
  LABEL_PATH = '/PATH/TO/labels.csv' # Ruta a archivo de etiquetas

  # Data
  TEST_SIZE = 0.2
  VAL_SIZE = 0.1

  labels = pd.read_csv(LABEL_PATH) # leemos archivo de etiquetas
  idx_to_class = dict(enumerate(labels.breed.unique())) # id -> clase
  class_to_idx = {c:i for i,c in idx_to_class.items()} # clase -> id

	# Model related
  LEARNING_RATE = 0.001
  MODEL = 'inception_v4'
  PRETRAINED = True

  # Trainer
  PRECISION = 16 # Float Precision
  MIN_EPOCHS = 1 # Min epochs
  MAX_EPOCHS = 3 # Max epochs
  ACCELERATOR = 'gpu' # Device
```

- Instanciamos el m√≥dulo Trainer

```python
import lightning as L

trainer = L.Trainer(
    accelerator=CFG.ACCELERATOR,
    devices=1, #¬†solo 1 device (gpu en nuestro caso)
    min_epochs=CFG.MIN_EPOCHS,
    max_epochs=CFG.MAX_EPOCHS,
    precision=CFG.PRECISION,
)
```

üöÄ¬†listo! ahora s√≥lo nos queda ejecutar el ansiado `.fit()`. Pero a√∫n falta algo importante ¬øComo sabremos que modelo es mejor? Nos basaremos en la m√©trica `Accuracy`. Pero ¬ødonde la monitorearemos? 

### üêù¬†Weight and Biases Logging

Weight and Biases (W&B) es una plataforma que permite realizar un seguimiento, visualizaci√≥n y colaboraci√≥n en proyectos de aprendizaje autom√°tico, lo que facilita el registro y el an√°lisis de experimentos y modelos de Machine Learning.

En este caso, la utilizaremos para monitorear las m√©tricas de nuestros modelos! Quiz√° en un futuro haga un blog de como utilizar esta maravillosa herramienta. En este caso es sencillo, s√≥lo debemos inicializar **Wandb logger**, y comunic√°rselo a nuestro m√≥dulo Trainer.

- Actualizamos CFG con la info de nuestro proyecto en WandB

```python
class CFG:
  IMG_PATH = 'PATH/TO/IMAGES' # Ruta a imagenes
  LABEL_PATH = '/PATH/TO/labels.csv' # Ruta a archivo de etiquetas

  # Data
  TEST_SIZE = 0.2
  VAL_SIZE = 0.1

  labels = pd.read_csv(LABEL_PATH) # leemos archivo de etiquetas
  idx_to_class = dict(enumerate(labels.breed.unique())) # id -> clase
  class_to_idx = {c:i for i,c in idx_to_class.items()} # clase -> id

  # Model related
  LEARNING_RATE = 0.001
  MODEL = 'inception_v4'
  PRETRAINED = True

  # Trainer
  PRECISION = 16 # Float Precision
  MIN_EPOCHS = 1 # Min epochs
  MAX_EPOCHS = 20 # Max epochs
  ACCELERATOR = 'gpu' # Device

  # Wandb related
  WANDB_PROJECT = 'My-wandb-project'
  WANDB_ENTITY = 'diegulio'
```

- Instanciamos el logger

```python
wandb_logger = WandbLogger(project = CFG.WANDB_PROJECT,
                           entity = CFG.WANDB_ENTITY,
                           name = f"{CFG.MODEL}_baseline", # exp name
                           log_model=False, # no guardar artefacto
                           config = wandb_config, # config
                           group = 'pretrained', #¬†grupo
                           job_type = 'training') # tipo de trabajo
```

- Agregamos el logger al Trainer

```python
trainer = L.Trainer(
    accelerator=CFG.ACCELERATOR,
    devices=1,
    min_epochs=CFG.MIN_EPOCHS,
    max_epochs=CFG.MAX_EPOCHS,
    precision=CFG.PRECISION,
    logger = wandb_logger, # Agregamos el logger
)
```

## 5. Fit

Ahora somos libres de entrenar!

```python
trainer.fit(model, train_dataloader, val_dataloader)
```

Veremos algo este estilo m√°s una barrita de carga:

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%205.png)

Observemos que la cantidad total de par√°metros es de 43.3 Millones ! A√∫n as√≠ nosotros s√≥lo entrenamos 2.1 Millones, y el resto lo congelamos ü•∂

## 6. Evaluate

Con Pytorch Lightning la evaluaci√≥n tambi√©n es sencilla ya que previamente establecimos el m√©todo `on_test_epoch_end()`. S√≥lo debemos ejectuar:

```python
trainer.test(model, test_dataloader)
```

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%206.png)

**Nota**: El test accuracy mostrado ac√° fue con el modelo sin pre-entrenar. Podemos notar lo mal que le fue debido a que necesitaba m√°s tiempo para converger.

# üéØ¬†Resultados

Todos los resultados los puedes ver en el [panel de Wandb](https://wandb.ai/diegulio/breed-classification-pytorch/workspace?workspace=user-diegulio) üêù¬†! 

Veamos el accuracy para los modelos baseline:

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%207.png)

Vemos que Inception_v4 se queda con el trono üëë¬†(para este caso de uso, claro) con un accuracy de un **85%** con s√≥lo 3 epochs!  Podemos ver un mont√≥n de otras m√©tricas en **Wandb**, incluso podemos ver que tanto c√≥mputo fue utilizado!

![M√©tricas de sistema en wandb](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%208.png)


El hecho de que haya tenido un buen performance con s√≥lo 3 iteraciones sobre el dataset, se lo debemos al uso de **Transfer Learning** üß†. 

En el panel, podr√°s ver que tambi√©n hice otros experimentos, en donde var√≠e algunos par√°metros, o agregu√© **Data Augmentation (**√âsta t√©cnica es muy poderosa, permitiendo al modelo poder generalizar mejor agreg√°ndole variaciones a las im√°genes.)

Luego de esto, el accuracy final fue de un **89%,** lo cual es totalmente mejorable**.** En el repositorio de Github podr√°s ver el c√≥digo final agreg√°ndole t√©cnicas como:

- Data Augmentation
- Custom Layers
- Learning Scheduler
- Early Stopping

# üßê¬†Front-End

::: {.callout-note icon=false}
## üêï‚Äçü¶∫ 
[Prueba la aplicaci√≥n ac√°](https://huggingface.co/spaces/Diegulio/breed-classification) !!
:::

Como siempre, no nos podemos quedar en puro c√≥digo, es por esto que utilizaremos **Gradio**  para poder crear una app utilizando nuestro modelo. Primero te dejar√© el c√≥digo, el cual es bastante sencillo gracias a Gradio!

```python
import gradio as gr
import torch
from torchvision import transforms

from app.backbone import Backbone
from app.config import CFG
from app.model import PetClassificationModel

# Cargamos modelos
backbone = Backbone(CFG.MODEL, len(CFG.idx_to_class), pretrained=CFG.PRETRAINED)
model = PetClassificationModel(base_model=backbone.model, config=CFG)
model.load_state_dict(torch.load("models/best_model.pt"))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Modo evaluacion
model.eval()

model.to(device)

# Funcion que cambia tama√±o de la imagen de entrada
pred_transforms = transforms.Compose(
    [
        transforms.Resize(CFG.IMG_SIZE),
        transforms.ToTensor(),
    ]
)

# Funci√≥n de predicci√≥n
def predict(x):
    x = pred_transforms(x).unsqueeze(0)  # transform and batched
    x = x.to(device)

    with torch.no_grad():
        prediction = torch.nn.functional.softmax(model(x)[0], dim=0)
        confidences = {
            CFG.idx_to_class[i]: float(prediction[i])
            for i in range(len(CFG.idx_to_class))
        }

    return confidences

# Interfaz Gradio
gr.Interface(
    fn=predict,
    title="Breed Classifier üê∂üß°üê±",
    description="Clasifica una imagen entre: 120 razas, gato o ninguno!",
    inputs=gr.Image(type="pil"),
    outputs=gr.Label(num_top_classes=5),
    examples=[
        "statics/pug.jpg",
        "statics/poodle.jpg",
        "statics/cat.jpg",
        "statics/no.jpg",
    ],
).launch()
```

Finalmente, nuestra aplicaci√≥n queda como:

![](Pytorch%20Breed%20Classification%20cf29b2ea83e645a897f1c0ae8daf3dbb/Untitled%209.png)

# üöÄ¬†Pr√≥ximos Pasos

Para mejorar la soluci√≥n podriamos intentar distintas t√©cnicas, algunas de estas son:

- **Unfreeze more layers:** Descongelar m√°s capas, esto suele ser efectivo cuando la tarea para la cual fue entrenado el modelo base es muy distinta a la tarea para la cual estamos trabajando.
- **M√°s Data Augmentation**: Si nuestro modelo generaliza mal, creando otros tipos de variaciones puede mejorar el performance de nuestro modelo
- **Agregar m√°s layers:** Podemos agregar m√°s capas en la parte de clasificaci√≥n, as√≠ pudiendo capturar patrones m√°s complejos. Esto puede ser efectivo en casos donde tu modelo est√© sufriendo de Underfitting.
- **Data Oriented**: En los datos, me di cuenta que hay algunas im√°genes mal etiquetadas,  esto puede provocar p√©rdida de performance. Un buen enfoque podr√≠a ser dedicarse a mejorar la calidad de los datos. Recordemos que si basura entra, basura sale.
- **Transformers**: Probar los nuevos modelos de computer vision basados en transformers (ViT).

# ü•≥¬†Conclusi√≥n

En este blog hemos abordado un desaf√≠o de clasificaci√≥n de im√°genes que abarca 120 razas de perros, la categor√≠a de gato y la opci√≥n "No detectado". Hemos demostrado c√≥mo PyTorch Lightning y la t√©cnica de transfer learning pueden simplificar dr√°sticamente el proceso de desarrollo y entrenamiento de modelos de Convolutional Neural Networks (CNN) preentrenados. Este enfoque nos ha permitido aprovechar el conocimiento previo de modelos preentrenados para resolver un problema altamente complejo y ha allanado el camino hacia soluciones efectivas y eficientes en tareas de clasificaci√≥n de im√°genes. Con estas herramientas a nuestro alcance, estamos preparados para abordar desaf√≠os a√∫n mayores y avanzar en la investigaci√≥n y aplicaciones del aprendizaje profundo en el mundo de la visi√≥n por computadora.

::: {.callout-note icon=false}
## ü§ñ 
conclusi√≥n creada por ChatGPT jeje
:::