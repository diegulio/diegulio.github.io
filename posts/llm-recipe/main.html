<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.333">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Diegulio">
<meta name="dcterms.date" content="2023-07-05">

<title>diegulio‚Äôs blogüéØ - Iniciando en LLM: Crea tu primera aplicaci√≥n con LangChain y ChatGPT</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../raccoon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">diegulio‚Äôs blogüéØ</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Iniciando en LLM: Crea tu primera aplicaci√≥n con LangChain y ChatGPT</h1>
            <p class="subtitle lead">Cocina tu comida favorita con la ayuda de LLM</p>
                                <div class="quarto-categories">
                <div class="quarto-category">python</div>
                <div class="quarto-category">llm</div>
                <div class="quarto-category">chatgpt</div>
                <div class="quarto-category">langchain</div>
                <div class="quarto-category">gradio</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Diegulio </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 5, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#llm-recipe" id="toc-llm-recipe" class="nav-link active" data-scroll-target="#llm-recipe">LLM Recipe</a></li>
  <li><a href="#t√≥pico-large-language-models" id="toc-t√≥pico-large-language-models" class="nav-link" data-scroll-target="#t√≥pico-large-language-models">üìö&nbsp;T√≥pico: Large Language Models</a></li>
  <li><a href="#motivaci√≥n-de-compras-con-llm" id="toc-motivaci√≥n-de-compras-con-llm" class="nav-link" data-scroll-target="#motivaci√≥n-de-compras-con-llm">üõí&nbsp;Motivaci√≥n: De compras con LLM</a></li>
  <li><a href="#tool-path-que-utilizaremos" id="toc-tool-path-que-utilizaremos" class="nav-link" data-scroll-target="#tool-path-que-utilizaremos">üî®&nbsp;Tool Path: Que utilizaremos</a></li>
  <li><a href="#concept-path-que-aprenderemos" id="toc-concept-path-que-aprenderemos" class="nav-link" data-scroll-target="#concept-path-que-aprenderemos">üí≠&nbsp;Concept Path: Que aprenderemos</a></li>
  <li><a href="#estrategia-como-abordamos" id="toc-estrategia-como-abordamos" class="nav-link" data-scroll-target="#estrategia-como-abordamos">‚ôüÔ∏è&nbsp;Estrategia: Como abordamos</a>
  <ul class="collapse">
  <li><a href="#prompt" id="toc-prompt" class="nav-link" data-scroll-target="#prompt">Prompt:</a></li>
  <li><a href="#output" id="toc-output" class="nav-link" data-scroll-target="#output">Output:</a></li>
  </ul></li>
  <li><a href="#tools" id="toc-tools" class="nav-link" data-scroll-target="#tools">üî®&nbsp;Tools</a></li>
  <li><a href="#prototyping" id="toc-prototyping" class="nav-link" data-scroll-target="#prototyping">üß†&nbsp;Prototyping</a>
  <ul class="collapse">
  <li><a href="#obtener-receta-mediante-llm" id="toc-obtener-receta-mediante-llm" class="nav-link" data-scroll-target="#obtener-receta-mediante-llm">1. Obtener receta mediante LLM</a>
  <ul class="collapse">
  <li><a href="#prompt-templates" id="toc-prompt-templates" class="nav-link" data-scroll-target="#prompt-templates">Prompt Templates</a></li>
  <li><a href="#code-time" id="toc-code-time" class="nav-link" data-scroll-target="#code-time">üë®üèæ‚Äçüíª&nbsp;Code time!</a></li>
  <li><a href="#llm-model" id="toc-llm-model" class="nav-link" data-scroll-target="#llm-model">LLM Model</a></li>
  </ul></li>
  <li><a href="#obtener-ingredientes-de-una-receta-mediante-llm" id="toc-obtener-ingredientes-de-una-receta-mediante-llm" class="nav-link" data-scroll-target="#obtener-ingredientes-de-una-receta-mediante-llm">2. Obtener ingredientes de una receta mediante LLM</a></li>
  <li><a href="#cadena-final" id="toc-cadena-final" class="nav-link" data-scroll-target="#cadena-final">3. Cadena Final</a></li>
  <li><a href="#output-parser" id="toc-output-parser" class="nav-link" data-scroll-target="#output-parser">4. Output Parser</a></li>
  </ul></li>
  <li><a href="#front-end" id="toc-front-end" class="nav-link" data-scroll-target="#front-end">üßê&nbsp;Front-End</a></li>
  <li><a href="#pr√≥ximos-pasos" id="toc-pr√≥ximos-pasos" class="nav-link" data-scroll-target="#pr√≥ximos-pasos">üöÄ&nbsp;Pr√≥ximos Pasos</a></li>
  <li><a href="#conclusi√≥n" id="toc-conclusi√≥n" class="nav-link" data-scroll-target="#conclusi√≥n">ü•≥&nbsp;Conclusi√≥n</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="llm-recipe" class="level1">
<h1>LLM Recipe</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://github.com/diegulio/llm-recipe"><img src="https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&amp;logo=github&amp;logoColor=white" class="img-fluid figure-img"></a></p>
</figure>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Antes de comenzar a leer esto, recuerda que yo estoy aprendiendo junto contigo. Si tienes alguna duda, sugerencia, correci√≥n o comentario, no dudes en escribirme a mi <a href="https://www.linkedin.com/in/dieguliomachado/">LinkedIn</a>.</p>
</div>
</div>
</section>
<section id="t√≥pico-large-language-models" class="level1">
<h1>üìö&nbsp;T√≥pico: Large Language Models</h1>
<p>Estoy seguro que alguna vez haz escuchado el t√©rmino ChatGPT. Yep! ese robot ü§ñ&nbsp;que te hace hasta la tesis! ChatGPT es un LLM (Large Language Model), lo que en otras palabras significa que es un modelo matem√°tico que se alimenta de grandes volumenes de texto y es capaz de generar lenguaje humano de manera muuy avanzada. Y si que lo hemos visto en acci√≥n, yo lo ocupo en mi dia a dia y me facilita un mont√≥n mi trabajo.</p>
<p>Ahora ¬ø Que tal si dejamos que un LLM nos describa que es un LLM?</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ü§ñ
</div>
</div>
<div class="callout-body-container callout-body">
<p>Un large language model (modelo de lenguaje amplio) es un tipo de sistema de inteligencia artificial dise√±ado para comprender y generar lenguaje humano de manera avanzada. Estos modelos est√°n entrenados en grandes cantidades de texto y utilizan t√©cnicas de aprendizaje autom√°tico para aprender patrones y estructuras ling√º√≠sticas. Un large language model, como GPT-3.5, puede responder preguntas, redactar textos, generar c√≥digo, traducir idiomas y realizar una variedad de tareas relacionadas con el lenguaje natural. Estos modelos son capaces de capturar la complejidad y sutileza del lenguaje humano, y pueden adaptarse a diferentes contextos y estilos de escritura.</p>
</div>
</div>
<p>En este post <strong>no</strong> hablaremos de las t√©cnicas utilizadas para construir un LLM, ya que en internet hay muy buenas fuentes para aprender sobre esto, ac√° te dejo una:</p>
<p><a href="https://docs.cohere.com/docs/llmu">LLM University (LLMU) | Cohere</a></p>
<p>Lo que haremos en este post, ser√° utilizar los LLM en el bien de la humanidad ! ü¶∏üèΩ‚Äç‚ôÄÔ∏è&nbsp;o quiz√° s√≥lo en nuestro bien.</p>
</section>
<section id="motivaci√≥n-de-compras-con-llm" class="level1">
<h1>üõí&nbsp;Motivaci√≥n: De compras con LLM</h1>
<p>El otro dia queria cocinar lasagna, pero no sabia si tenia los ingredientes en casa. En realidad, no queria gastar ning√∫n ingrediente en casa, por lo que me met√≠ a la website de mi supermercado favorito para comprar los ingredientes. El problema es que nunca he cocinado lasagna por lo que no s√© que ingredientes lleva! me di√≥ tanta flojera googlear una receta, extraer los ingredientes y ponerlos uno por uno en el carrito de compras que termin√© comiendo cereales con leche ü•£.</p>
<p>Ah√≠ fue cuando pens√© que ser√≠a bueno que el supermercado tuviese integrado un algoritmo que agregue autom√°ticamente los ingredientes de una comida espec√≠fica en el carrito de compras! üõçÔ∏è</p>
<p>üß†&nbsp;<strong>Soluci√≥n: Utilizar LLM para obtener recetas y extraer los ingredientes de forma estructurada.</strong></p>
<p>La verdad esto fue una excusa para comenzar a aprender a utilizar los LLM, el mundo se est√° moviendo en torno a esto y no pienso quedarme atr√°s.</p>
</section>
<section id="tool-path-que-utilizaremos" class="level1">
<h1>üî®&nbsp;Tool Path: Que utilizaremos</h1>
<p>A continuaci√≥n les dejo las herramientas que utilizaremos en este post:</p>
<ol type="1">
<li><strong>ChatGPT API</strong>: Para poder acceder a los poderes de ChatGPT</li>
<li><strong>LangChain</strong>: Para poder comunicarme de manera f√°cil con la API de ChatGPT, adem√°s de aprovechar un mont√≥n de los facilitadores que tiene para construir herramientas basadas en LLM</li>
<li><strong>Python</strong>: Lenguaje de programaci√≥n</li>
<li><strong>Gradio</strong>: Para crear una interfaz simple de uso</li>
</ol>
</section>
<section id="concept-path-que-aprenderemos" class="level1">
<h1>üí≠&nbsp;Concept Path: Que aprenderemos</h1>
<p>A continuaci√≥n algunos de los conceptos que aprenderemos:</p>
<ol type="1">
<li>LLM: Ya hablamos un poco sobre esto</li>
<li>Prompt Engineering</li>
<li>Prompt Templates</li>
<li>Chains</li>
<li>Environments</li>
<li>Framework</li>
</ol>
<p>La verdad esto es un primer paso para aprender LLM, hay muchos conceptos m√°s all√° que a√∫n queda por explorar, y lo peor es que esto sigue avanzando a pasos agigantados. ü¶∂üèΩ</p>
</section>
<section id="estrategia-como-abordamos" class="level1">
<h1>‚ôüÔ∏è&nbsp;Estrategia: Como abordamos</h1>
<p>La soluci√≥n es bastante directa, pedirle a alg√∫n LLM que nos entregue los ingredientes de una comida especifica</p>
<section id="prompt" class="level2">
<h2 class="anchored" data-anchor-id="prompt">Prompt:</h2>
<p>Imaginemos queremos saber los ingredientes para cocinar una lasagna, entonces escribiremos algo del estilo:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üë©üèº‚Äçüî¨
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øQue necesito para cocinar una Lasagna?</p>
</div>
</div>
<p>Esta pregunta, que es la entrada de un LLM se le denomina <code>prompt.</code> Un t√©rmino bastante conocido hasta ahora, que de hecho se asocia a un rol, es <code>Prompt Engineering</code>. Podemos entender este t√©rmino como el ‚Äúarte‚Äù de escribir el mejor prompt para obtener la respuesta deseada.</p>
<p>‚ÄúCuida la forma en la que pides las cosas‚Äù me dec√≠a mi mam√° cuando ni√±o al pedirle un favor a alguien. Las mam√°s siempre tienen la raz√≥n, y esta no es la excepci√≥n.</p>
<p>Imaginemos que la respuesta de la LLM es algo como:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ü§ñ
</div>
</div>
<div class="callout-body-container callout-body">
<p>Para cocinar una lasagna necesitas un horno, un cuchillo, una cocina y los ingredientes.</p>
</div>
</div>
<p>No es la respuesta que esperabamos! nosotros en realidad quer√≠amos saber los ingredientes, pero nos expresamos mal. Es por esto que com√∫nmente se suele iterar el prompt hasta conseguir la respuesta deseada, imaginemos que luego de iterar un poco llegamos al prompt final:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üë©üèº‚Äçüî¨
</div>
</div>
<div class="callout-body-container callout-body">
<p>¬øCuales son los ingredientes que necesito para cocinar una lasagna?</p>
</div>
</div>
<p>Probablemente con un prompt as√≠ obtengamos lo que buscamos. No hay un prompt √≥ptimo, pero si existen muchos prompt que nos conseguir√°n la respuesta que buscamos.</p>
<p>M√°s adelante veremos algunas t√©cnicas de prompt engineering. Por ahora nos basta con saber que el prompt ser√° elemento importante de nuestra soluci√≥n.</p>
</section>
<section id="output" class="level2">
<h2 class="anchored" data-anchor-id="output">Output:</h2>
<p>Algo que nos debemos cuestionar es: ¬øComo necesitamos el resultado? algunas de las opciones son: Una lista de ingredientes, un json, un DataFrame, etc.</p>
<p>En este caso lo que decid√≠ fue obtener un json, el cual luego convertir√≠a a un DataFrame. Los elementos que tendr√° la respuesta son:</p>
<ul>
<li><strong>Ingredient</strong>: Nombre del ingrediente</li>
<li><strong>Quantity</strong>: Cantidad necesaria</li>
<li><strong>Optional</strong>: ‚ÄúYes‚Äù si el ingrediente es opcional, ‚ÄúNo‚Äù si es obligatorio</li>
<li><strong>Estimated Price</strong>: Un precio estimado en d√≥lares del ingrediente (as√≠ podremos calcular alg√∫n valor aproximado de la receta)</li>
<li><strong>Available</strong>: Una simulaci√≥n de disponibilidad del ingrediente en el supermercado. ‚ÄúYes‚Äù si est√° disponible, ‚ÄúNo‚Äù si no lo est√°.</li>
</ul>
<p>Ac√° tenemos un ejemplo:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"Spaguetthi With Meat"</span><span class="fu">:</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">[</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ingredient"</span><span class="fu">:</span> <span class="st">"Spaguetti"</span><span class="fu">,</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"optional"</span><span class="fu">:</span> <span class="st">"No"</span><span class="fu">,</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"quantity"</span><span class="fu">:</span> <span class="st">"200g"</span><span class="fu">,</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"estimated_price"</span><span class="fu">:</span> <span class="st">"5.00"</span><span class="fu">,</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"available"</span><span class="fu">:</span> <span class="st">"No"</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span><span class="ot">,</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ingredient"</span><span class="fu">:</span> <span class="st">"Meat"</span><span class="fu">,</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"optional"</span><span class="fu">:</span> <span class="st">"No"</span><span class="fu">,</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"quantity"</span><span class="fu">:</span> <span class="st">"1kg"</span><span class="fu">,</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"estimated_price"</span><span class="fu">:</span> <span class="st">"10.00"</span><span class="fu">,</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"available"</span><span class="fu">:</span> <span class="st">"Yes"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span><span class="ot">,</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ingredient"</span><span class="fu">:</span> <span class="st">"Pepper"</span><span class="fu">,</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"optional"</span><span class="fu">:</span> <span class="st">"Yes"</span><span class="fu">,</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"quantity"</span><span class="fu">:</span> <span class="st">"at ease"</span><span class="fu">,</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"estimated_price"</span><span class="fu">:</span> <span class="st">"1.00"</span><span class="fu">,</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"available"</span><span class="fu">:</span> <span class="st">"No"</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="ot">]</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Una pregunta importante es, ¬øC√≥mo lograremos que el LLM nos estructure el output como lo requerimos?</p>
<p><strong>SPOILER: Prompt Engineering</strong></p>
</section>
</section>
<section id="tools" class="level1">
<h1>üî®&nbsp;Tools</h1>
<p>En este post no busco explicar a fondo las herramientas que utilizar√©, si no que mostrar su uso. Para entender m√°s sobre ellas te dejar√© enlaces a sus propias documentaciones (probablemente mucho mejor explicado como lo har√≠a yo).</p>
<p>A continuaci√≥n mencionar√© un poco sobre las herramientas que utilizaremos en las siguientes secciones:</p>
<ul>
<li><strong>Langchain</strong>: LangChain es un framework dise√±ado para simplificar la creaci√≥n de aplicaciones utilizando modelos de lenguaje grandes (LLM). Como framework de integraci√≥n del modelo de lenguaje, los casos de uso de LangChain se superponen en gran medida con los de los modelos de lenguaje en general, incluidos el an√°lisis y resumen de documentos, los chatbots y el an√°lisis de c√≥digo.</li>
<li><strong>ChatGPT API</strong>: ChatGPT API es una interfaz de programaci√≥n de aplicaciones (API) que permite a los desarrolladores interactuar con el modelo de lenguaje ChatGPT de OpenAI. Esta API permite enviar solicitudes a trav√©s de una conexi√≥n de red para obtener respuestas generadas por el modelo en tiempo real. Al utilizar la API, los desarrolladores pueden integrar f√°cilmente la funcionalidad de ChatGPT en sus propias aplicaciones, productos o servicios. Proporciona una manera conveniente de aprovechar la potencia de ChatGPT para tareas como conversaci√≥n, generaci√≥n de texto y respuestas a preguntas en una amplia gama de aplicaciones y escenarios.</li>
</ul>
</section>
<section id="prototyping" class="level1">
<h1>üß†&nbsp;Prototyping</h1>
<p>La forma final en la que plantearemos la soluci√≥n ser√°:</p>
<ol type="1">
<li>Usar un LLM que obtenga la receta seg√∫n la comida</li>
<li>Usar un LLM que obtenga los ingredientes de la receta obtenida del paso 1</li>
<li>Crear la cadena final de LLM. Esto es, unir los resultados de los pasos 1 y 2.</li>
<li>Parsear los resultados. Esto es, estructurarlos.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>üëÄ Inicialmente habia pensado en que un LLM directamente me entregue los ingredientes desde una comida especificada, pero luego de unas cuantas iteraciones llegu√© a que de la forma en base a chains consegu√≠a mejores resultados</p>
</div>
</div>
<section id="obtener-receta-mediante-llm" class="level2">
<h2 class="anchored" data-anchor-id="obtener-receta-mediante-llm">1. Obtener receta mediante LLM</h2>
<section id="prompt-templates" class="level3">
<h3 class="anchored" data-anchor-id="prompt-templates">Prompt Templates</h3>
<p>En este punto vale la pena preguntarnos, c√≥mo esperamos que el usuario interact√∫e con nuestra aplicaci√≥n? Queremos que el usuario haga la pregunta completa? Ahora sabemos que esto no es una buena idea por varias razones:</p>
<ol type="1">
<li>El usuario podria ingresar incluso preguntas que no est√©n relacionadas con la aplicaci√≥n (comida)</li>
<li>El usuario puede preguntar de forma ineficiente</li>
<li>Obtener la estructura json que deseamos ser√≠a imposible</li>
<li>El usuario no sabe de <code>Prompt Engineering</code></li>
</ol>
<p>La idea es que el usuario s√≥lo ingrese el nombre de la comida, y por detr√°s nuestra aplicaci√≥n haga el resto. Para esto, Langchain cuenta con una herramienta llamada Prompt Templates, que como su nombre lo indica es una plantilla del prompt.</p>
<p>Esto es, imaginemos nuestra plantilla es: ‚Äú¬øCuales son los ingredientes que necesito para cocinar {COMIDA}?‚Äù Entonces si la entrada del usuario es ‚ÄúLasagna‚Äù, el prompt quedar√° ‚Äú¬øCuales son los ingredientes que necesito para cocinar <em>Lasagna</em>?‚Äù.</p>
</section>
<section id="code-time" class="level3">
<h3 class="anchored" data-anchor-id="code-time">üë®üèæ‚Äçüíª&nbsp;Code time!</h3>
<p>Para crear un template, primero debemos definir la estructura:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>template_string <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="st">Give me a list of ingredients to cook </span><span class="sc">{food}</span><span class="st">.</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Notemos que el input en este caso es ‚Äúfood‚Äù. Luego usamos Langchain</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.prompts <span class="im">import</span> PromptTemplate</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>prompt_template <span class="op">=</span> PromptTemplate.from_template(template_string)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Luego simplemente obtenemos el prompt final para entregarle al modelo de la siguiente forma:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>user_input <span class="op">=</span> <span class="st">'Lasagna'</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>final_prompt <span class="op">=</span> prompt.<span class="bu">format</span>(food<span class="op">=</span>user_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As√≠ de simple! Ahora quiero que nos compliquemos un poco m√°s la vida. ChatGPT hizo unos cambios en su API, por lo que en Langchain ahora aparece un nuevo elemento llamado <code>ChatPromptTemplate</code></p>
<p>La idea de este template, que si bien tambi√©n acepta entradas como las vistas anteriormente, ahora permite ingresar mensajes con <code>roles</code>. Existen tres tipos de roles: System, Human, AI. Bien brevemente te explico que deberian ser:</p>
<ul>
<li>System Message: Las instrucciones que se le quiere entregar al modelo</li>
<li>Human Message: Las entradas del usuario</li>
<li>AI Message: Alguna respuesta por parte de el modelo</li>
</ul>
<p>Ac√° te dejo un post del por qu√© de esta implementaci√≥n, que viene de la mano con <code>ChatModels</code>: <a href="https://blog.langchain.dev/chat-models/">https://blog.langchain.dev/chat-models/</a></p>
<p>Debido a que s√≥lo el paso 1 utiliza input de usuario, s√≥lo lo haremos as√≠ en este paso:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.prompts <span class="im">import</span> (</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    ChatPromptTemplate,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    PromptTemplate,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    SystemMessagePromptTemplate,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    AIMessagePromptTemplate,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    HumanMessagePromptTemplate,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;System template</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>first_system_template_str <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="st">    You are a good chef, users need you to bring them recipes from given food.</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>first_system_template <span class="op">=</span> SystemMessagePromptTemplate.from_template(first_system_template_str)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Human Template</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>first_human_template_str <span class="op">=</span> <span class="st">"</span><span class="sc">{food}</span><span class="st">"</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>first_human_template <span class="op">=</span> HumanMessagePromptTemplate.from_template(first_human_template_str)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># First Prompt Template</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>first_prompt <span class="op">=</span> ChatPromptTemplate.from_messages([first_system_template, first_human_template])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="llm-model" class="level3">
<h3 class="anchored" data-anchor-id="llm-model">LLM Model</h3>
<p>Ahora que ya tenemos una entrada para nuestro modelo, necesitamos llamarlo!</p>
<p>Para poder hacer uso de un modelo de LLM (En este caso ChatOpenAI) primero debemos crearnos una cuenta en <a href="https://openai.com/blog/openai-api">openai</a> y crear una nueva API Key. Luego, debemos crear un archivo <code>.env</code> en la ra√≠z del proyecto con el siguiente contenido:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">OPENAI_API_KEY</span> = <span class="st">"&lt;tu api key&gt;"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>No debes dejar que nadie vea tu API KEY, asi que no subas tu .env a ning√∫n lugar p√∫blico!</p>
</div>
</div>
<p>Si no, puedes agregarlo directamente utilizando la libreria openai o Langchain.Luego de obtener y entregar tu API KEY, en Langchain basta con hacer algo como:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Porfavor hazme la tesis!"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> chat(prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>En este caso, estaremos utilizando dos LLM, en donde la salida de una es la entrada de otra. Langchain ya tiene algo preparado para esto! se les llama Chains. En este caso, tenemos una cadena simple (Dos LLM secuenciales), pero existen otros tipos de arquitecturas mucho m√°s complejas ‚ò†Ô∏è</p>
<p>Para poder crear nuestra primera Chain no es tanto m√°s complejo que el ejemplo anterior, s√≥lo debemos agregar unos pasos extras:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> LLMChain</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># LLM Definition</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Chain Step 1</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>recipe_chain <span class="op">=</span> LLMChain(llm<span class="op">=</span>llm, prompt<span class="op">=</span>first_prompt, output_key<span class="op">=</span><span class="st">"recipe"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>En el c√≥digo anterior estamos utilizando la LLM ChatOpenAI, y creando la primera parte de la cadena. El par√°metro <code>output_key</code> nos servir√° m√°s adelante para comunicarle a la segunda parte cual es el nombre del primer output.</p>
</section>
</section>
<section id="obtener-ingredientes-de-una-receta-mediante-llm" class="level2">
<h2 class="anchored" data-anchor-id="obtener-ingredientes-de-una-receta-mediante-llm">2. Obtener ingredientes de una receta mediante LLM</h2>
<p>Ya sabemos que la salida del paso anterior ser√° una receta, a la cual deberemos extraer los ingredientes. Adem√°s, √©ste es el √∫ltimo paso, por lo que deberemos preocuparnos de que el output que salga del LLM sea adecuado y simple de ‚Äúparsear‚Äù.</p>
<p>Para el output, lo que haremos ser√° aplicar un poco del ya conocido <code>prompt engineering</code>.</p>
<p>Adem√°s, en este caso, ya que no existen tantos riesgos de <code>prompt injection</code> , es que usaremos templates sencillos (no haremos uso de los roles en los mensajes)</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>second_step_template <span class="op">=</span> <span class="st">"""I need you to bring me the ingredients contained in the following recipe: </span><span class="ch">\</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="st">recipe: </span><span class="sc">{recipe}</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="sc">{format_instructions}</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="sc">{example_instructions}</span><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Vemos que tenemos tres entradas:</p>
<ul>
<li>recipe: Este input ser√° el resultado del paso anterior.</li>
<li>format_instructions: Ac√° le comunicaremos al LLM como queremos el formato del output.</li>
<li>example_instructions: Ac√° aplicamos un poco de lo que se llama <code>few-shot</code> , que es b√°sicamente darle un par de ejemplos al LLM para que entienda como esperamos el resultado.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Format Instructions</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>custom_format_instructions <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="st">The output should be in a json format, formatted in the following schema:</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="st">{</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="st">  "food": List // List of ingredients</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="st">  [</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="st">      "ingredient": string // Name of one ingredient</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="st">      "quantity": string  // Quantity of the ingredient </span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="st">      "optional": string  // Whether or not that ingredient is optional to cook the food. "Yes" if the ingredient is not indispensable to cook, "No" if is the ingredient is indispensable.</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="st">      "estimated_price": string  // The ingredient's estimated price in dolars</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="st">      "available": string // Random "Yes" or "No"</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="st">  ]</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>    example_instructions <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="st">Follow the schema of this example:</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="st">{</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="st">  "food":</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="st">  [</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="st">      "ingredient": "Spaguetti",</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="st">      "optional": "No",</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="st">      "quantity": "200g",</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="st">      "estimated_price": "5.00",</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="st">      "available": "No"</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="st">      "ingredient": "Meat",</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="st">      "optional": "No",</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="st">      "quantity": "1kg",</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="st">      "estimated_price": "10.00",</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="st">      "available": "Yes"</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="st">      "ingredient": "Pepper",</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="st">      "optional": "Yes",</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="st">      "quantity": "at ease",</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="st">      "estimated_price": "1.00",</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="st">      "available": "No"</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="st">  ]</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>‚úãüèΩ Es importante que sepas que langchain cuenta con un m√≥dulo de Output parser que crea por detr√°s el format_instructions e incluso cuenta con funciones que transforman la salida del LLM(string) en el formato que deseabamos (json, lista, Pydantic, etc). La raz√≥n de porqu√© yo no ocup√© esto fue que no funciona para json nesteados. Pero me bas√© en sus instrucciones para crear <code>custom_format_instructions</code></p>
</div>
</div>
<p>Luego seguimos como lo vimos anteriormente:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>second_prompt <span class="op">=</span> ChatPromptTemplate.from_template(second_step_template)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>ingredient_chain <span class="op">=</span> LLMChain(llm<span class="op">=</span>llm, prompt<span class="op">=</span>second_prompt, output_key<span class="op">=</span><span class="st">"ingredients"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="cadena-final" class="level2">
<h2 class="anchored" data-anchor-id="cadena-final">3. Cadena Final</h2>
<p>Luego necesitamos orquestar las cadenas que creamos anteriormente para obtener la cadena final. En Langchain se hace de la siguiente forma:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>overall_simple_chain <span class="op">=</span> SequentialChain(chains<span class="op">=</span>[recipe_chain, ingredient_chain], verbose<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                                       input_variables<span class="op">=</span>[<span class="st">"food"</span>, <span class="st">"format_instructions"</span>, <span class="st">"example_instructions"</span>],</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                                       output_variables<span class="op">=</span>[<span class="st">"recipe"</span>, <span class="st">"ingredients"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="output-parser" class="level2">
<h2 class="anchored" data-anchor-id="output-parser">4. Output Parser</h2>
<p>Finalmente, necesitamos parsear el resultado obtenido desde la LLM. Esto es <strong><em>string ‚Üí json.</em></strong></p>
<p>Debido a la forma en que le pedimos el resultado al LLM, es que se nos hace muy sencillo:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> overall_simple_chain(</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"food"</span>: food, <span class="co"># Esto lo entrega el usuario</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"format_instructions"</span>: custom_format_instructions, <span class="co"># Esto lo entregamos nosotros</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_instructions"</span>: example_instructions, <span class="co"># Esto lo entregamos nosotros</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># String to json(dict en python)</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>dict_response <span class="op">=</span> json.loads(result[<span class="st">'ingredients'</span>]) </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Dict to df</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>output_df <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> dict_response[<span class="st">'food'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finalmente, para la entrada ‚ÄúLasagna‚Äù, podemos obtener algo asi:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="LLM Recipe ee36a92d74c24a5d986142d48f3b51c8/Untitled.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Output 1 as DataFrame</figcaption>
</figure>
</div>
</section>
</section>
<section id="front-end" class="level1">
<h1>üßê&nbsp;Front-End</h1>
<p>Nuestra aplicaci√≥n no puede quedarse s√≥lo en c√≥digo, es por esto que creamos un peque√±o front-end para los usuarios. A continuaci√≥n te dejo una imagen, pero lo mejor es que corras el c√≥digo por ti mismo y los pruebes! Te invito a mejorar el algoritmo!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="LLM Recipe ee36a92d74c24a5d986142d48f3b51c8/Untitled 1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Input and Output 0</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="LLM Recipe ee36a92d74c24a5d986142d48f3b51c8/Untitled 2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Output 1</figcaption>
</figure>
</div>
<p>Notar que en el front-end se le entrega al usuario tanto la receta como el resumen de los ingredientes. Algo interesante de gradio es el bot√≥n <code>Avisar</code>. Este bot√≥n sirve para recibir feedback de los usuarios en caso de que el resultado no haya sido satisfactorio, y as√≠ puedes mejorar tu producto.</p>
</section>
<section id="pr√≥ximos-pasos" class="level1">
<h1>üöÄ&nbsp;Pr√≥ximos Pasos</h1>
<p>Esto es s√≥lo una soluci√≥n inicial, podemos mejorarla de muchas formas, algunas que se me ocurren por ahora son:</p>
<ul>
<li>Prompt Optimization: Mejorar m√°s los prompt. Quiz√° agregarle el hecho de que una persona puede ingresar algo que no es una comida. Podemos simplemente decirle ‚ÄúSi piensas que no es una comida, entrega este resultado..‚Äù</li>
<li>Fine-Tuning: Podriamos entrenar un LLM con datos de recetarios</li>
<li>Document: Podriamos hacer que el LLM considere un libro de recetas en particular a la hora de crear su respuesta. Quiz√° tambi√©n agregarle productos propios del supermercado para incentivar su compra. Esto es desafiante debido a que un documento tiene muchos caracteres y los LLM tienen un limite llamado <code>context_length</code>. Afortunadamente ya existen metodolog√≠as para sobrellevar esto.</li>
</ul>
</section>
<section id="conclusi√≥n" class="level1">
<h1>ü•≥&nbsp;Conclusi√≥n</h1>
<p>En este blog exploramos el mundo de los Large Language Models (LLM) y su aplicaci√≥n en la vida cotidiana. El LLM m√°s conocido, ChatGPT, es un modelo matem√°tico capaz de comprender y generar lenguaje humano de manera avanzada. Descubrimos c√≥mo utilizar los LLM para obtener recetas y extraer los ingredientes de forma estructurada, utilizando t√©cnicas de Prompt Engineering.</p>
<p>Mediante el uso de herramientas como LangChain, Python y Gradio, pudimos construir una soluci√≥n que permite al usuario ingresar el nombre de una comida y obtener autom√°ticamente los ingredientes necesarios para cocinarla. Utilizando Prompt Templates y Chains, logramos interactuar con el modelo de manera eficiente y obtener respuestas precisas.</p>
<p>Aunque esta soluci√≥n es solo un primer paso en el mundo de los LLM, demuestra el potencial de estos modelos para simplificar tareas y mejorar nuestra vida diaria. A medida que la tecnolog√≠a avance, seguiremos explorando nuevas aplicaciones y t√©cnicas para aprovechar al m√°ximo los Large Language Models en beneficio de la humanidad.</p>
<p>Recuerda que en github podr√°s encontrar el c√≥digo utilizado en este proyecto.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>