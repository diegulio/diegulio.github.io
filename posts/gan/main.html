<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.21">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Diegulio">
<meta name="dcterms.date" content="2024-02-28">

<title>Paper Implementation Series: Generative Adversarial Networks ‚Äì üéØ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo3.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-f9d2e688c83043042fa051765c26f29b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-67839544912bc898267f15026188952a.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-f9d2e688c83043042fa051765c26f29b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1e494f7d463c62844c0a5ba0ca2952b9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-2bc1395d7f116208967e2be16dafdae1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-1e494f7d463c62844c0a5ba0ca2952b9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Paper Implementation Series: Generative Adversarial Networks ‚Äì üéØ">
<meta property="og:description" content="Implementamos el paper Generative Adversarial Networks">
<meta property="og:image" content="https://diegulio.github.io/posts/gan/paper.jpeg">
<meta property="og:site_name" content="üéØ">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo3.png" alt="" class="navbar-logo light-content">
    <img src="../../logo3.png" alt="" class="navbar-logo dark-content">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">üéØ</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/diegulio"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/dieguliomachado/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Paper Implementation Series: Generative Adversarial Networks</h1>
            <p class="subtitle lead">Implementamos el paper Generative Adversarial Networks</p>
                                <div class="quarto-categories">
                <div class="quarto-category">python</div>
                <div class="quarto-category">pytorch</div>
                <div class="quarto-category">paper</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Diegulio </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 28, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#t√≥pico-gan-paper-implementation" id="toc-t√≥pico-gan-paper-implementation" class="nav-link active" data-scroll-target="#t√≥pico-gan-paper-implementation">üìù T√≥pico: GAN Paper Implementation</a></li>
  <li><a href="#motivaci√≥n-implementar-un-paper" id="toc-motivaci√≥n-implementar-un-paper" class="nav-link" data-scroll-target="#motivaci√≥n-implementar-un-paper">Motivaci√≥n: Implementar un Paper</a></li>
  <li><a href="#tool-path-que-utilizaremos" id="toc-tool-path-que-utilizaremos" class="nav-link" data-scroll-target="#tool-path-que-utilizaremos">üî®&nbsp;Tool Path: Que utilizaremos</a></li>
  <li><a href="#concept-path-que-aprenderemos" id="toc-concept-path-que-aprenderemos" class="nav-link" data-scroll-target="#concept-path-que-aprenderemos">üí≠&nbsp;Concept Path: Que aprenderemos</a></li>
  <li><a href="#estrategia-como-abordamos" id="toc-estrategia-como-abordamos" class="nav-link" data-scroll-target="#estrategia-como-abordamos">‚ôüÔ∏è&nbsp;Estrategia: Como abordamos</a></li>
  <li><a href="#prototyping-gan" id="toc-prototyping-gan" class="nav-link" data-scroll-target="#prototyping-gan">üß†&nbsp;Prototyping: GAN</a>
  <ul class="collapse">
  <li><a href="#generative-adversarial-networks" id="toc-generative-adversarial-networks" class="nav-link" data-scroll-target="#generative-adversarial-networks">Generative Adversarial Networks</a></li>
  <li><a href="#implementando-gan" id="toc-implementando-gan" class="nav-link" data-scroll-target="#implementando-gan">üë®üèæ‚Äçüíª&nbsp;Implementando GAN</a>
  <ul class="collapse">
  <li><a href="#generador" id="toc-generador" class="nav-link" data-scroll-target="#generador">1. Generador</a></li>
  <li><a href="#discriminador" id="toc-discriminador" class="nav-link" data-scroll-target="#discriminador">2. Discriminador</a></li>
  <li><a href="#rutina-de-entrenamiento" id="toc-rutina-de-entrenamiento" class="nav-link" data-scroll-target="#rutina-de-entrenamiento">3. Rutina de Entrenamiento</a></li>
  <li><a href="#resultados" id="toc-resultados" class="nav-link" data-scroll-target="#resultados">4. Resultados</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#dcgan" id="toc-dcgan" class="nav-link" data-scroll-target="#dcgan">DCGAN</a></li>
  <li><a href="#conclusiones" id="toc-conclusiones" class="nav-link" data-scroll-target="#conclusiones">Conclusiones</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">






<p><a href="https://github.com/diegulio/paper_implementations"><img src="https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&amp;logo=github&amp;logoColor=white" class="img-fluid"></a></p>
<section id="t√≥pico-gan-paper-implementation" class="level1">
<h1>üìù T√≥pico: GAN Paper Implementation</h1>
<p>En este post, implementaremos un paper (SPOILER: en realidad ser√°n 2) desde 0, esto con el fin de mostrar todo lo que se puede aprender de este proyecto y motivar al lector a intentarlo. Intentar√© narrar este post como un ‚Äúdiario de vida‚Äù, mostrando los desaf√≠os que super√©, y los que no. Los papers a implementar en esta ocasi√≥n ser√°n:</p>
<ul>
<li><a href="https://arxiv.org/abs/1406.2661"><strong>Generative Adversarial Networks</strong></a></li>
<li><strong><a href="https://arxiv.org/abs/1511.06434">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></strong></li>
</ul>
<p>Eleg√≠ el primero ya que evalu√© que era un paper totalmente implementable desde el punto de vista t√©cnico, era un modelo y algoritmo ‚Äúsimple‚Äù de implementar y no se necesitar√≠a mucho c√≥mputo. El segundo lo implement√© s√≥lo con la intenci√≥n de mejorar los resultados del primero, y con el objetivo de seguir aprendiendo!</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>‚ö†Ô∏è
</div>
</div>
<div class="callout-body-container callout-body">
<p>No me centrar√© demasiado en aspectos t√©cnicos de alto nivel, como el uso b√°sico de Pytorch. El lector puede consultar internet o mi post <strong><a href="https://diegulio.github.io/posts/pytorch_breed_classification/main.html">Image Classification with Pytorch Lightning</a></strong> si est√° interesado</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>üõë
</div>
</div>
<div class="callout-body-container callout-body">
<p>DISCLAIMER: En este paper no muestro <strong>c√≥mo implementar</strong> un paper, si no m√°s bien como lo implement√© yo, desde mi conocimiento, por lo que me disculpo de antemano si algo de lo que habr√© hecho fue ineficiente o incorrecto y agradecer√© un mont√≥n si me informan cualquier sugerencia! ‚ù§Ô∏è</p>
</div>
</div>
</section>
<section id="motivaci√≥n-implementar-un-paper" class="level1">
<h1>Motivaci√≥n: Implementar un Paper</h1>
<p>Una muy buena pr√°ctica que grandes mentes en tecnolog√≠a normalmente recomiendan es implementar un paper. Esto hace mucho sentido, ya que con esto realmente nos ensuciamos las manos con los algoritmos, ponemos atenci√≥n a detalles t√©cnicos, aprendemos nuevas metodolog√≠as, mejora sustancialmente nuestros skills t√©cnicos, y finalmente nos ayuda a leer mejor los papers. Incluso en muchas publicaciones de trabajo en las big tech es un requisito</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/interview.png" class="img-fluid figure-img"></p>
<figcaption>AI Post</figcaption>
</figure>
</div>
<p>Personalmente, a veces navego por Kaggle viendo soluciones, donde muchas veces los ganadores utilizan soluciones hechas ‚Äúa mano‚Äù. Con esto me refiero a no simplemente llamar un modelo y ejecutar el <code>.fit()</code> , si no que crear la estructura de tu modelo desde 0, e incluso innovar en la rutina de entrenamiento. En ocasiones, los puntitos de performance que se gana con esto hace la diferencia en el Leaderboard.</p>
<p>La ofuscaci√≥n me recorre cuando me doy cuenta que yo no ser√≠a capaz de implementar algo as√≠ (siempre lo pienso sin siquiera intentarlo). Es por esto que me decid√≠ a pasar por este proceso, y me propuse implementar un paper que me llame la atenci√≥n, y apuntar a obtener los mismos resultados (caso ideal).</p>
<p>En este post, no quiero s√≥lo mostrar la soluci√≥n final, porque siento que eso desalienta al lector, haci√©ndolo creer que llegu√© a la soluci√≥n al primer intento. En esta ocasi√≥n, mostrar√© la mayor√≠a de los desaf√≠os por los que tuve que pasar, los √©xitos y los fracasos; el paso a paso de como llegu√© a lo que ser√≠a mi soluci√≥n final.</p>
</section>
<section id="tool-path-que-utilizaremos" class="level1">
<h1>üî®&nbsp;Tool Path: Que utilizaremos</h1>
<p>A continuaci√≥n les dejo las herramientas que utilizaremos en este post:</p>
<ol type="1">
<li><strong>Pytorch</strong>: es una biblioteca de c√≥digo abierto para el desarrollo de aplicaciones de aprendizaje profundo y la investigaci√≥n en inteligencia artificial.</li>
</ol>
</section>
<section id="concept-path-que-aprenderemos" class="level1">
<h1>üí≠&nbsp;Concept Path: Que aprenderemos</h1>
<p>A continuaci√≥n algunos de los conceptos que veremos:</p>
<ol type="1">
<li>Generative Adversarial Networks</li>
<li>Convolutional Neural Networks (Pr√≥ximamente üò¢)
<ol type="1">
<li>Downsampling</li>
<li>Upsampling</li>
</ol></li>
</ol>
</section>
<section id="estrategia-como-abordamos" class="level1">
<h1>‚ôüÔ∏è&nbsp;Estrategia: Como abordamos</h1>
<p>La estrategia fue la siguiente.</p>
<ol type="1">
<li><strong>Vencer el S√≠ndrome del Impostor</strong>: Tarea dif√≠cil, por ahora met√°monos en la cabeza que nosotros tambi√©n somos capaces de crear cosas, y que no es tan dif√≠cil como lo creemos. Ahora es el momento en que lo comprobamos.</li>
<li><strong>Buscar un Paper para leer</strong>: Ac√° debemos considerar algunas limitaciones.</li>
<li><strong>Leer el Paper:</strong> Existen algunos tips en la forma de leer un paper.</li>
<li><strong>Implementar</strong>: Ac√° se encuentra la complejidad t√©cnica.</li>
<li><strong>Ver resultados</strong>: A cruzar los dedos y esperar tener resultados similares ü§ûüèΩ</li>
</ol>
</section>
<section id="prototyping-gan" class="level1">
<h1>üß†&nbsp;Prototyping: GAN</h1>
<p>Comenzaremos con el paper Generative Adversarial Networks. Yo no soy experto en leer papers, existen algunos tips para esto, como el saltarse algunas secciones que pueden no ser muy interesantes o el orden en el cual deberiamos leer, pero todo esto normalmente es para ocasiones en donde estas leyendo para conocer el estado del arte. En este momento, ya que queremos implementar la soluci√≥n, yo simplemente opt√© por leer todo el paper (no es tan largo).</p>
<p>A medida lo le√≠a, intentaba entender todo lo necesario para implementarlo, cada vez que no entend√≠a alg√∫n t√©rmino o t√©cnica utilizada, lo googleaba, esto me llev√≥ a aprender muchas cosas nuevas.</p>
<section id="generative-adversarial-networks" class="level2">
<h2 class="anchored" data-anchor-id="generative-adversarial-networks">Generative Adversarial Networks</h2>
<p>A grandes rasgos, en este paper muestran un nuevo camino para la generaci√≥n de datos. Es importante que s√≥lo le digamos camino, porque no buscan traer la mejor soluci√≥n que promete superar a todo, si no que remarcan que el objetivo es dar a conocer una forma prometedora en la que se podr√≠a generar datos, y que con el tiempo podria traer grandes resultados con ayuda de la comunidad investigadora. No s√≥lo generar im√°genes, si no tambi√©n otros tipos de datos como audio o texto.</p>
<p>Efectivamente, esta metodolog√≠a marc√≥ un antes y un despu√©s para la generaci√≥n de im√°genes, que luego fue superada por los modelos de difusi√≥n debido a la inestabilidad y dificultad de entrenamiento que las GAN traen. A√∫n as√≠, la comunidad mejor√≥ este primer paper trayendo una gran cantidad de GANs al mundo, logrando grandiosos resultados (DCGAN, cGAN, styleGAN, CycleGAN, etc)</p>
<p>En resumen, esta metodolog√≠a consta de 2 modelos, un <strong>Generador</strong> y un <strong>Discriminador</strong>. La misi√≥n del <strong>Generador</strong> es, como lo indica su nombre, generar im√°genes (a partir de aqu√≠ solo hablaremos de im√°genes) que sigan la misma distribuci√≥n que el conjunto de datos, esto de forma indirecta, ya que en realidad lo entrenamos para que logre enga√±ar al <strong>Discriminador.</strong> El <strong>Discriminador</strong>, por otro lado, es entrenado para clasificar entre im√°genes provenientes de la data real e im√°genes generadas por el <strong>Generador</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled.png" class="img-fluid figure-img"></p>
<figcaption>Generative Adversarial Networks</figcaption>
</figure>
</div>
<p>En la pr√≥xima secci√≥n comenzaremos a construir esta metodolog√≠a.</p>
</section>
<section id="implementando-gan" class="level2">
<h2 class="anchored" data-anchor-id="implementando-gan">üë®üèæ‚Äçüíª&nbsp;Implementando GAN</h2>
<p>Seg√∫n el paper, para implementar la soluci√≥n, necesitamos 3 componentes:</p>
<ol type="1">
<li>Generador</li>
<li>Discriminador</li>
<li>Rutina de Entrenamiento</li>
</ol>
<p>El objetivo es construir un modelo que genere im√°genes que provengan de la misma distribuci√≥n que nuestro conjunto de datos (que se parezcan). En esta ocasi√≥n utilizaremos el conocido conjunto de datos MNIST, ya que es uno de los utilizados en el paper y es bastante simple de encontrar y utilizar.</p>
<blockquote class="blockquote">
<p>We trained adversarial nets an a range of datasets including MNIST[23], the Toronto Face Database(TFD) [28], and CIFAR-10 [21].</p>
</blockquote>
<p>Ac√° un vistazo de como luce el conjunto de datos MNIST (son im√°genes de n√∫meros escritos a mano)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 1.png" class="img-fluid figure-img"></p>
<figcaption>MNIST Dataset</figcaption>
</figure>
</div>
<section id="generador" class="level3">
<h3 class="anchored" data-anchor-id="generador">1. Generador</h3>
<p>Leamos que dice el paper sobre esto:</p>
<blockquote class="blockquote">
<p>To learn the generator‚Äôs distribution <span class="math inline">\(p_g\)</span> over data <span class="math inline">\(x\)</span>, we define a prior on input noise variables <span class="math inline">\(p_z(z)\)</span>, then represent a mapping to data space as <span class="math inline">\(G(z;\theta_g)\)</span>, where <span class="math inline">\(G\)</span> is a differentiable function represented by a multilayer perceptron with parameters <span class="math inline">\(\theta_g\)</span>.</p>
</blockquote>
<p>Lo que se entiende de ac√° es que nosotros definiremos una distribuci√≥n a priori para el input <span class="math inline">\(z\)</span> del generador <span class="math inline">\(G\)</span>. Este ruido <span class="math inline">\(z\)</span> es luego transformado por el Generador (una red neuronal) para obtener una imagen generada que sigue la distribuci√≥n <span class="math inline">\(p_g\)</span>. Nuestro objetivo entonces es que la distribuci√≥n <span class="math inline">\(p_g = p_{data}\)</span> , esto tambi√©n lo podemos concluir de el extracto del paper:</p>
<blockquote class="blockquote">
<p>The generator <span class="math inline">\(G\)</span> implicitly defines a probability distribution <span class="math inline">\(p_g\)</span> as the distribution of the samples <span class="math inline">\(G(z)\)</span> obtained when <span class="math inline">\(z‚àºp_z\)</span>. Therefore, we would like Algorithm 1 to converge to a good estimator of <span class="math inline">\(p_{data}\)</span>, if given enough capacity and training time.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 2.png" class="img-fluid figure-img"></p>
<figcaption>Generator</figcaption>
</figure>
</div>
<p>No se ven tan complicado, ahora veamos m√°s detalles sobre el generador en si:</p>
<blockquote class="blockquote">
<p>The generator nets used a mixture of rectifier linear activations [19,9] and sigmoid activations ‚Ä¶. While our theoretical framework permits the use of dropout and other noise at intermediate layers of the generator, we used noise as the input to only the bottommost layer of the generator network.</p>
</blockquote>
<p>Ac√° nos topamos con la primera complejidad: No tenemos muchos detalles. Bien podemos ver que no nos dan informaci√≥n sobre cuantos layers tiene el MLP, cuantas neuronas cada layer, ni como transformamos el resultado a una imagen! Esto √∫ltimo era bastante confuso para mi, en primera instancia creia que se utilizaban Convolutional Neural Networks, pero luego me di cuenta que no era necesariamente as√≠.</p>
<p>Creo que el motivo del por qu√© no hay tanto detalle en el modelo, es que buscan dejarlo abierto a que la comunidad comience a explorar y experimentar con esta arquitectura de soluci√≥n.</p>
<p>Adem√°s del paper, me apoy√© de algunos otros blogs donde explicaban este modelo, la mayor√≠a hablaba directamente de Convolutional Neural Networks. A√∫n as√≠, me quise apegar lo m√°s posible al paper y descart√© esta soluci√≥n por el momento. Incluso el paper sugiere el uso de CNN bien sutilmente cuando escriben lo siguiente en el pie de foto de los resultados</p>
<blockquote class="blockquote">
<ol start="4" type="a">
<li>CIFAR-10 (convolutional discriminator and ‚Äúdeconvolutional‚Äù generator)</li>
</ol>
</blockquote>
<p>√âsta era la √∫nica pista de que al menos para CIFAR-10 utilizaron redes convolucionales.</p>
<p>Luego de algunas iteraciones, llegu√© a la conclusi√≥n que ser√≠a algo como lo siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 3.png" class="img-fluid figure-img"></p>
<figcaption>Generation of an Image from Noise</figcaption>
</figure>
</div>
<p>La operaci√≥n ser√≠a:</p>
<ol type="1">
<li>Obtenemos <span class="math inline">\(noise\)</span> vector de la distribuci√≥n a priori <span class="math inline">\(p_z\)</span> de dimensi√≥n <span class="math inline">\(latent\_size\)</span> (la distribuci√≥n a priori suele ser gaussiana o uniforme)</li>
<li>Pasamos el vector por una red neuronal (NN)</li>
<li>Transformamos el vector final proveniente del √∫ltimo layer de la NN a las dimensiones de la imagen ( un simple <code>.reshape(img_size)</code>)</li>
</ol>
<p>Vamos a ver el c√≥digo ! ü§ñü§ñü§ñ</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Noise Vector</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> torch.randn(LATENT_SIZE)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Generator NN</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generator model: In charge of generate </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    real-like images from a noise distribution</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_size, img_size):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Generator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># layers to use</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            nn.Linear(latent_size, <span class="dv">128</span>),  <span class="co"># Nx100</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(),</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">128</span>,<span class="dv">256</span>), <span class="co"># Nx256</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">256</span>),</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, <span class="dv">512</span>), <span class="co"># Nx512</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">512</span>),</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">1024</span>), <span class="co"># Nx1024</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">1024</span>),</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(),</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, img_size<span class="op">*</span>img_size), <span class="co"># Nx28*28</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            nn.Tanh()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model(x)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Generate Img</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> G(noise.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> out.view(IMG_SIZE, IMG_SIZE)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.imshow(img.detach().numpy(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Con el modelo sin entrenar, el resultado es algo del estilo:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 4.png" class="img-fluid figure-img"></p>
<figcaption>Generated Image from nontrained Generator</figcaption>
</figure>
</div>
<p>Ser√° muy interesante ver como el modelo evoluciona de tal manera que pueda convertir este ruido en im√°genes parecidas al conjunto de datos!</p>
<p><strong>Observaciones üëÄ</strong></p>
<ol type="1">
<li>Las dimensiones del conjunto de datos MNIST es (28x28x1) ‚Üí son im√°genes en blanco y negro</li>
<li>Notar que la √∫ltima capa debe tener una dimensi√≥n de salida igual a la dimensi√≥n de la imagen, esto con el objetivo de poder moldear(reshape) el vector resultante a la imagen. Esto es, el vector de salida debe ser de <span class="math inline">\(28*28*1=784\)</span></li>
<li>Al comienzo utilic√© ReLU como funci√≥n de activaci√≥n, en el paper dicen: <em>The generator nets used a mixture of rectifier linear activations</em>. Pero luego de algunas iteraciones vi que era mejor LeakyReLU</li>
<li>Al comienzo no utilic√© BatchNorm, pero tambi√©n me di cuenta (navegando por internet) que era importante para este tipo de modelo para estabilidad y convergencia.</li>
<li>La salida de el modelo es pasado por una funci√≥n <span class="math inline">\(Tanh()\)</span> para que se encuentre en un rango [-1,1]. Las im√°genes originales tambi√©n son normalizadas previamente para que pertenezcan a este rango.</li>
<li>LATENT_SIZE suele ser 100</li>
<li>Importante mencionar que al principio s√≥lo comenc√© con unas cuantas capas, y fui iterando hasta llegar a la arquitectura mostrada arriba seg√∫n los resultados y experimentos de otras personas.</li>
<li>En el paper DCGAN (veremos m√°s adelante), mencionan que el modelo se ve beneficiado al utilizar BatchNorm en todas las capas menos en la primera del Generador y la √∫ltima del Discriminador.</li>
</ol>
</section>
<section id="discriminador" class="level3">
<h3 class="anchored" data-anchor-id="discriminador">2. Discriminador</h3>
<p>Ya tenemos el modelo que generar√° imagenes y que intentar√° enga√±ar al Discriminador. El Discriminador es bastante m√°s sencillo, s√≥lo debemos pensar que es un clasificador de im√°genes tal y como lo conocemos. Esto es, recibimos una imagen (pixeles), y devolvemos una clase (0 si es fake, 1 si es real)</p>
<p>El paper dice lo siguiente del Discriminador D:</p>
<blockquote class="blockquote">
<p>We also define a second multilayer perceptron <span class="math inline">\(D(x;\theta_d)\)</span> that outputs a single scalar. <span class="math inline">\(D(x)\)</span>represents the probability that <span class="math inline">\(x\)</span> came from the data rather than <span class="math inline">\(p_g\)</span>. We train D to maximize the probability of assigning the correct label to both training examples and samples from G.</p>
</blockquote>
<p>En c√∫anto a los detalles, s√≥lo tenemos :</p>
<blockquote class="blockquote">
<p>while the discriminator net used maxout [10] activations. Dropout [17] was applied in training the discriminator net.</p>
</blockquote>
<p>Si lo visualizamos, ser√≠a algo como:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 5.png" class="img-fluid figure-img"></p>
<figcaption>Discriminator</figcaption>
</figure>
</div>
<p>El proceso es el siguiente:</p>
<ol type="1">
<li>La entrada puede ser una imagen real proveniente del dataset (<span class="math inline">\(p_{data}\)</span>) o proveniente del Generador (<span class="math inline">\(p_{g}\)</span>)</li>
<li>La Imagen entra al Discriminador (NN)</li>
<li>El resultado es una probabilidad [0,1], en donde 0 es imagen fake y 1 real.</li>
</ol>
<p>Es algo as√≠ como el proceso contrario de el Generador. Vamos al c√≥digo!</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#0. Define MaxOut Activation</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MaxOut(nn.Module):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_units, num_pieces):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MaxOut, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_units <span class="op">=</span> num_units</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_pieces <span class="op">=</span> num_pieces</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(num_units, num_units <span class="op">*</span> num_pieces)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape the output to separate pieces</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        maxout_output <span class="op">=</span> <span class="va">self</span>.fc(x).view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_pieces, <span class="va">self</span>.num_units)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Take the maximum value across pieces</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        output, _ <span class="op">=</span> torch.<span class="bu">max</span>(maxout_output, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Imagen o Imagen Generada</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>out <span class="co"># Esto viene del Generador que hicimos arriba (o de el dataset original)</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Discriminador</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generator model: In charge of classify</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">    images between real and syntetic generated</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">    by the generator </span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, img_size):</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Discriminator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>            nn.Linear(img_size<span class="op">*</span>img_size, <span class="dv">512</span>), <span class="co">#N x 512</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            MaxOut(<span class="dv">512</span>, <span class="dv">4</span>),</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">256</span>), <span class="co"># N x 256</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>            MaxOut(<span class="dv">256</span>, <span class="dv">4</span>),</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, <span class="dv">1</span>), <span class="co"># N x 1</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>            nn.Sigmoid()</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model(x)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Se predice</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> Discriminator()</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> D(out)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>El resultado es simple, ser√° algo como 0.495. Algo as√≠ como que es tan probable que sea una imagen real como fake seg√∫n el discriminador. Al comienzo puede ser as√≠ ya que no est√° entrenado.</p>
<p><strong>Observaciones üëÄ</strong></p>
<ol type="1">
<li>La entrada es la misma dimensi√≥n que la salida del Generador (784)</li>
<li>Ac√° no utilizamos BatchNorm (aunque si deb√≠ hacerlo seg√∫n el paper DCGAN)</li>
<li>Utilizamos MaxOut activation como lo indica el paper, √©ste no se encuentra por defecto en Pytorch, por lo que hay que definirlo ‚Äúa mano‚Äù</li>
<li>Olvid√© utilizar Dropout como lo recomienda el paper, esto podr√≠a mejorar los resultados, al igual que agregar BatchNorm</li>
<li>Al igual que en el Generador, la arquitectura se fue iterando seg√∫n resultados.</li>
</ol>
</section>
<section id="rutina-de-entrenamiento" class="level3">
<h3 class="anchored" data-anchor-id="rutina-de-entrenamiento">3. Rutina de Entrenamiento</h3>
<p>Una vez tenemos el Generador y el Discriminador, s√≥lo nos queda entrenar. Seg√∫n el paper (lo que entend√≠), no lo hacen de la forma tradicional (iterando sobre el dataset original). Ellos proponen lo siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 6.png" class="img-fluid figure-img"></p>
<figcaption>GAN Training Algorithm</figcaption>
</figure>
</div>
<p>Proponen, en cada iteraci√≥n, primero optimizar el Discriminador por K pasos:</p>
<ol type="1">
<li>Extraen un minibatch de imagenes reales</li>
<li>Extraen un minibatch de imagenes generadas por G</li>
<li>Hacen un update en base a Gradient Ascent</li>
</ol>
<p>Luego, optimizan el Generador en un s√≥lo paso:</p>
<ol type="1">
<li>Extrae un minibatch de imagenes generadas por G</li>
<li>Hacen un update de los par√°metros en base a Gradient Descend</li>
</ol>
<p>Seg√∫n indican en el paper, updatean m√°s veces el Discriminador, ya que buscan que el Discriminador se mantenga cercano al √≥ptimo mientras el Generador se va actualizando lentamente hasta converger.</p>
<blockquote class="blockquote">
<p>This results in D being maintained near its optimal solution, so long as G changes slowly enough.</p>
</blockquote>
<p>Lo que vemos ac√°, es que el generador actualiza sus par√°metros utilizando informaci√≥n implicita entregada por el Discriminador. Optimizamos el Generador para lograr enga√±ar al Discriminador.</p>
<p>Algo importante a poner atenci√≥n, es la funci√≥n objetivo, que tenemos 2, la del discriminador y la del generador, vamos a ver esto con m√°s detalle.</p>
<hr>
<p><strong>Loss Functions üìé</strong></p>
<p><strong>Discriminador</strong></p>
<p>Recordemos que el Discriminador <span class="math inline">\(D\)</span> es un clasificador com√∫n, por lo que podemos utilizar la funci√≥n com√∫n para estos casos (Cross Entropy Loss). Desentra√±emos esto hasta llegar a lo que tienen en el paper:</p>
<p>Queremos clasificar correctamente los positivos (imagenes reales) y negativos (imagenes generadas), la funci√≥n objetivo Binary Cross Entropy est√° dada por:</p>
<p><span class="math display">\[
-\dfrac{1}{m} \sum{y_ilog(\hat{y_i}) + (1-y_i)log(1-\hat{y_i})}
\]</span></p>
<p>donde <span class="math inline">\(y_i\)</span> es el label (0 o 1) de la imagen i ; <span class="math inline">\(\hat{y_i}\)</span> es la predicci√≥n de la imagen i, fake o real ; <span class="math inline">\(m\)</span> es el tama√±o del minibatch</p>
<p>Notemos que</p>
<ul>
<li>cuando <span class="math inline">\(y_i = 1\)</span>, la imagen <span class="math inline">\(x_i\)</span> es real , osea que <span class="math inline">\(\hat{y_i} = D(x_i)\)</span> y lo de la derecha es 0 en la ecuaci√≥n</li>
<li>cuando <span class="math inline">\(y_i=0\)</span>, la imagen <span class="math inline">\(G(z_i)\)</span> es fake ,osea que <span class="math inline">\(\hat{y_i} = D(G(z_i))\)</span> y lo de la izquierda es 0 en la ecuaci√≥n</li>
</ul>
<p>Es por esto que podemos reducir la ecuaci√≥n a:</p>
<p><span class="math display">\[
Min -\dfrac{1}{m} \sum{ log(D(x_i)) + log(1-D(G(z_i)))}
\]</span></p>
<p>Si bien esto se puede traducir a que queremos maximizar</p>
<p><span class="math display">\[
Max \dfrac{1}{m} \sum{ log(D(x_i)) + log(1-D(G(z_i)))}
\]</span></p>
<p>tal como sale en el paper (sin el signo negativo), por conveniencia no lo haremos y optaremos por minimizar el Binary Cross Entropy y asi el c√≥digo se reduce a utilizar la funci√≥n ya hecha en Pytorch <code>BCELoss()</code> quedando algo como</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>BCELoss([D(x), D(G(z))], [<span class="dv">1</span>, <span class="dv">0</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Otras soluciones optan por optimizarlas por separado, o por promediar ambos. En mi caso las concaten√© junto con sus targets.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>üí°
</div>
</div>
<div class="callout-body-container callout-body">
<p>Maximizar una funci√≥n Z es equivalente a Minimizar -Z</p>
</div>
</div>
<p><strong>Generador</strong></p>
<p>Para el generador, es similar, s√≥lo que ahora s√≥lo le entregamos im√°genes falsas y adem√°s queremos que <span class="math inline">\(D\)</span> se equivoque. Por lo tanto, maximizamos la funci√≥n de p√©rdida Binary Cross Entropy (que se equivoque), y s√≥lo observamos cuando <span class="math inline">\(y_i = 0\)</span> (s√≥lo im√°genes falsas), teniendo</p>
<p><span class="math display">\[
Max -\dfrac{1}{m} \sum{  log(1-D(G(z_i)))}
\]</span></p>
<p>Ahora lo llevamos a minimizar por conveniencia en c√≥digo (en Pytorch por defecto se busca minimizar la funci√≥n objetivo)</p>
<p><span class="math display">\[
Min \dfrac{1}{m} \sum{  log(1-D(G(z_i)))}
\]</span></p>
<p>obteniendo lo que aparece en el paper. En c√≥digo ser√≠a algo como</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>BCELoss(D(G(z)), <span class="dv">0</span>) <span class="co"># El signo - es porque implicitamente maximizamos BCE</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
<p>Fuaaa, cuanta matem√°tica ü§Øü§Øü§Ø, comprobemos esto de forma intuitiva:</p>
<p>Para el <strong>Discriminador</strong> tenemos entonces:</p>
<p><span class="math display">\[
Max \dfrac{1}{m} \sum{ log(D(x_i)) + log(1-D(G(z_i)))}
\]</span></p>
<p>si lo separamos, queremos entonces:</p>
<p><span class="math display">\[
Max \dfrac{1}{m} \sum{ log(D(x_i)) }
\]</span></p>
<p><span class="math display">\[
Max \dfrac{1}{m} \sum{ log(1-D(G(z_i)) }
\]</span></p>
<p>La primera funci√≥n (olvidando la suma y eso) es <span class="math inline">\(ln(x)\)</span> ‚Üí si, la base utilizada es la exponencial, por lo que es el logaritmo natural. Su gr√°fica es:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Notes_240225_163331.jpg" class="img-fluid figure-img"></p>
<figcaption>ln(x)</figcaption>
</figure>
</div>
<p>El eje horizontal es <span class="math inline">\(D(x_i)\)</span>: <em>La probabilidad de que la imagen real <span class="math inline">\(x_i\)</span> sea clasificada como real</em>, con un rango [0,1]. Ya que la imagen es real, queremos que D prediga un valor alto (ojal√° 1), lo que si vemos la gr√°fica es igual a alcanzar el m√°ximo de la funci√≥n (<code>m√°x optimo</code>). Es por esto que maximizamos <span class="math inline">\(\dfrac{1}{m} \sum{ log(D(x_i)) }\)</span></p>
<p>Ahora vamos con <span class="math inline">\(log(1-D(G(z_i))\)</span> , cuya gr√°fica es:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 7.png" class="img-fluid figure-img"></p>
<figcaption>ln(1-x) Discriminador</figcaption>
</figure>
</div>
<p>Ahora la gr√°fica cambia, el eje horizontal est√° dado por <span class="math inline">\(D(G(z_i))\)</span>: <em>La probabilidad de que la imagen falsa <span class="math inline">\(G(z_i)\)</span> sea clasificada como <strong>real. V</strong></em>emos que la funci√≥n se maximiza cuando <span class="math inline">\(D(G(z_i))\)</span> se acerca a 0, y esto es lo que queremos porque <span class="math inline">\(G(z_i)\)</span> es una imagen falsa y debe ser clasificada como tal en el Discriminador (ojal√° 0). Es por esto que buscamos maximizar <span class="math inline">\(\dfrac{1}{m} \sum{ log(1-D(G(z_i)) }\)</span></p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>üî•
</div>
</div>
<div class="callout-body-container callout-body">
<p>IMPORTANTE! Ac√° vemos la funci√≥n objetivo tal y como est√° en el paper (maximizando), pero en el c√≥digo, por conveniencia, lo llevamos a minimizar la BCELoss, lo cual es equivalente, tal como lo mostramos en la parte matem√°tica. √âsto en los gr√°ficos es parecido s√≥lo que ahora buscamos minimizar ambas partes, dejar√© este ejercicio como tarea para el lector!</p>
</div>
</div>
<p>Para el <strong>Generador</strong>, es muy similar a la segunda ecuaci√≥n del Discriminador, s√≥lo que ahora buscamos minimizar (ir hacia a la derecha).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 8.png" class="img-fluid figure-img"></p>
<figcaption>ln(1-x) Generador</figcaption>
</figure>
</div>
<p>Vemos que la idea es ir hacia la derecha porque queremos que el Discriminador se equivoque, o sea que aunque le entreguemos una imagen falsa <span class="math inline">\(D(G(z_i))\)</span>, el discriminador prediga que es real (se acerque a 1). Si vemos bien, a medida <span class="math inline">\(D(G(z_i))\)</span> se acerca a 1, la funci√≥n <span class="math inline">\(\dfrac{1}{m} \sum{  log(1-D(G(z_i)))}\)</span> se acerca a Esto puede provocar inestabilidad en la optimizaci√≥n, y es por esto que mucha gente utiliza la equivalencia:</p>
<p><span class="math display">\[
Min \dfrac{1}{m} \sum{ log(D(G(z_i))) }
\]</span></p>
<p>como funci√≥n objetivo de el Generador. Ac√° vemos que utilizamos la parte donde <span class="math inline">\(y_i = 1\)</span> , osea que la imagen es real, pero minimizamos haciendo que el Discriminador diga que es falsa. Intuitivamente se pierde un poco el sentido ya que en realidad la imagen entregada no es real, pero matem√°ticamente es equivalente y logra mayor estabilidad y al minimizar el √≥ptimo es 0 y no <span class="math inline">\(-\infin\)</span> (a√∫n as√≠ yo utilic√© la primera forma)</p>
<p>Espero esta secci√≥n se haya entendido, es un tanto complicado de escribir con palabras. El proceso de entendimiento de la funci√≥n objetivo, fue un proceso bastante entretenido e interesante, que sin duda me sirvi√≥ para mejorar algunas aptitudes a la hora de leer papers. A√∫n as√≠ mencionar que es importante apoyarse en la literatura (libros, blogs, papers), el objetivo no es comprobar que tu podr√≠as haber llegado a las mismas conclusiones que los autores por tu lado, si no que eres capaz de entender (matem√°tica- o intuitiva- mente) lo que se propone. Invito al lector a iniciar una conversaci√≥n conmigo si le qued√≥ alguna duda, o si not√≥ que pude haberme equivocado en algo.</p>
<hr>
<p><strong>Train</strong> üèãüèæ</p>
<p>Ahora ya podemos comenzar a entrenar el modelo, primero vamos a inicializar algunos componentes importantes:</p>
<ol type="1">
<li>Configuraci√≥n</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CFG</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>latent_size <span class="op">=</span> <span class="dv">100</span> <span class="co"># noise dimension</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> <span class="dv">28</span> <span class="co"># image shape</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="co"># GPU</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20000</span> <span class="co"># TRAINING ITERATIONS</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">1</span> <span class="co"># Discriminator steps</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ol type="1">
<li><strong>Modelos:</strong> Utilizamos los modelos construidos anteriormente</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Models </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> Generator(cfg.latent_dim, cfg.img_size)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> Discriminator(cfg.img_size)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>G.to(cfg.device)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>D.to(cfg.device)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ol type="1">
<li><strong>Loss Functions</strong>: Recordemos que gracias a que re-definimos la matem√°tica de las funciones objetivos, podemos ocupar la funci√≥n pre-construida en Pytorch <code>BCELoss()</code></li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Losses</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>D_LOSS <span class="op">=</span> nn.BCELoss()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>G_LOSS <span class="op">=</span> nn.BCELoss()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ol type="1">
<li><strong>Optimizadores</strong>: Utilizamos Adam, con un learning rate bastante m√°s peque√±o que el usual y unos betas espec√≠ficos. Esto es uno de los problemas de GAN, es muy sensible a los hyperpar√°metros, cuando normalmente los modelos (Deeplearning) son robustos a estos.</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizers</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>d_optimizer <span class="op">=</span> torch.optim.Adam(D.parameters(), lr <span class="op">=</span> <span class="fl">0.0002</span>, betas <span class="op">=</span> (<span class="fl">0.5</span>, <span class="fl">0.999</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>g_optimizer <span class="op">=</span> torch.optim.Adam(G.parameters(), lr <span class="op">=</span> <span class="fl">0.0002</span>, betas <span class="op">=</span> (<span class="fl">0.5</span>, <span class="fl">0.999</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ol type="1">
<li><strong>Dataset</strong>: Ya que MNIST es bastante conocido, ya se encuentra disponible en Pytorch para descargar</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Datasets (Images and Noise)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((cfg.img_size, cfg.img_size)),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),  <span class="co"># Convert PIL image or numpy array to tensor</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>,), (<span class="fl">0.5</span>,))  <span class="co"># Normalize the tensor with mean and standard deviation</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> MNIST(root <span class="op">=</span> <span class="st">''</span>, download <span class="op">=</span> <span class="va">True</span>, transform <span class="op">=</span>transform )</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> RandomSampler(dataset) <span class="co"># To get random images each iteration</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoader</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>original_dl <span class="op">=</span> DataLoader(dataset, batch_size <span class="op">=</span> cfg.batch_size, sampler <span class="op">=</span> sampler, pin_memory<span class="op">=</span>torch.cuda.is_available())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Notar que ac√° normalizamos las im√°genes para que est√©n en el rango [-1,1] y nos aseguramos que tengan el mismo tama√±o 28x28. Tambi√©n, ya que no iremos avanzando batch por batch, iremos sampleando aleatoriamente el dataset tal como lo dice la rutina de entrenamiento pertenciente al paper.</p>
<ol type="1">
<li>Rutina de entrenamiento: Iremos sentencia por sentencia navegando la rutina de entrenamiento y codeando!</li>
</ol>
<blockquote class="blockquote">
<p><em>for number of training iterations do</em></p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(cfg.epochs):</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>for k steps do</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(cfg.epochs):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>Sample minibatch of m noise samples {z(1), . . . , z(m)} from noise prior <span class="math inline">\(p_g(z)\)</span>.</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(cfg.epochs):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># noise minibatch </span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>Sample minibatch of m examples {x(1), . . . , x(m)} from data generating distribution <span class="math inline">\(p_{data}(x)\)</span></p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(cfg.epochs):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># noise minibatch </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># original minibatch</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(original_dl))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>Update the discriminator by ascending its stochastic gradient</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(cfg.epochs):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># noise minibatch </span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># original minibatch</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(original_dl))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">## Discriminator Optimization </span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        d_optimizer.zero_grad()</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        G_z <span class="op">=</span> G(z) <span class="co"># Generated Image</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        D_x  <span class="op">=</span> D(x) <span class="co"># real image's probability of being real</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        D_G_z <span class="op">=</span> D(G_z.detach()) <span class="co"># fake image's probability of being real</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concat real and fakes</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.cat([D_G_z, D_x]).to(cfg.device)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make targets (1 for real, 0 for fakes)</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> torch.cat([torch.zeros(D_G_z.size()[<span class="dv">0</span>]), torch.ones(D_x.size()[<span class="dv">0</span>])]).to(cfg.device)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Discriminator Loss</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loss</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> D_LOSS(samples, targets.unsqueeze(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        d_loss.backward() <span class="co"># backward</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Adjust learning weights</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>End for. Sample minibatch of m noise samples {z(1), . . . , z(m)} from noise prior <span class="math inline">\(p_g(z)\)</span>.</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(cfg.epochs)):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># noise minibatch </span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># original minibatch</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(original_dl))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">## Discriminator Optimization </span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        d_optimizer.zero_grad()</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        G_z <span class="op">=</span> G(z) <span class="co"># Generated Image</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        D_x  <span class="op">=</span> D(x) <span class="co"># real image's probability of being real</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        D_G_z <span class="op">=</span> D(G_z.detach()) <span class="co"># fake image's probability of being real</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concat real and fakes</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.cat([D_G_z, D_x]).to(cfg.device)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># make targets (1 for real, 0 for fakes)</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> torch.cat([torch.zeros(D_G_z.size()[<span class="dv">0</span>]), torch.ones(D_x.size()[<span class="dv">0</span>])]).to(cfg.device)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Discriminator Loss</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loss</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> D_LOSS(samples, targets.unsqueeze(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>        d_loss.backward() <span class="co"># backward</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Adjust learning weights</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Minibatch from noise prior</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim).to(cfg.device)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>Update the generator by descending its stochastic gradient:</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(cfg.epochs)):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(cfg.k):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># noise minibatch </span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># original minibatch</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(original_dl))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">## Discriminator Optimization </span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">##############################</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        d_optimizer.zero_grad()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        G_z <span class="op">=</span> G(z) <span class="co"># Generated Image</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        D_x  <span class="op">=</span> D(x) <span class="co"># real image's probability of being real</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        D_G_z <span class="op">=</span> D(G_z.detach()) <span class="co"># fake image's probability of being real</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concat real and fakes</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.cat([D_G_z, D_x]).to(cfg.device)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># make targets (1 for real, 0 for fakes)</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> torch.cat([torch.zeros(D_G_z.size()[<span class="dv">0</span>]), torch.ones(D_x.size()[<span class="dv">0</span>])]).to(cfg.device)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Discriminator Loss</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loss</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> D_LOSS(samples, targets.unsqueeze(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        d_loss.backward() <span class="co"># backward</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Adjust learning weights</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Minibatch from noise prior</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.randn(batch_size, cfg.latent_dim).to(cfg.device)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Generator Optimization </span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    g_optimizer.zero_grad()</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    G_z <span class="op">=</span> G(z) <span class="co"># Generated Images</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    D_G_z <span class="op">=</span> D(G_z) <span class="co"># fake/generated image's probability of being real</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># targets</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> torch.zeros(D_G_z.size()[<span class="dv">0</span>]).to(cfg.device)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loss</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    g_loss <span class="op">=</span> <span class="op">-</span>G_LOSS(D_G_z, targets.unsqueeze(<span class="op">-</span><span class="dv">1</span>)) <span class="co"># Max BCE</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    g_loss.backward()</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust learning weights</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    g_optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Y con eso ya estamos! a correr y a observar los resultados, a continuaci√≥n algunas observaciones:</p>
<ol type="1">
<li>Tambi√©n se puede hacer el entrenamiento com√∫n (minibatch stochastic gradient descend )</li>
<li>Vi que en algunos lados utilizan el mismo noise <span class="math inline">\(z\)</span> para ambas partes de la optimizaci√≥n</li>
<li>En la linea <code>D_G_z = D(G_z.detach())</code> , el .detach() es para no actualizar parametros del Generador en la parte del Discriminador, por lo que quitamos G_z de del grafo computacional.</li>
<li>Entren√© por 20.000 iteraciones! se demor√≥ aprox 15 minutos. Notemos que no son epochs (pasadas por el training set), si no que s√≥lo iteraciones del algoritmo.</li>
</ol>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>‚ö†Ô∏è
</div>
</div>
<div class="callout-body-container callout-body">
<p>WARNING: Si quieres utilizar el c√≥digo, te recomiendo verlo directamente desde Github ya que ac√° quit√© algunas cosas para que se pueda entender mejor</p>
</div>
</div>
</section>
<section id="resultados" class="level3">
<h3 class="anchored" data-anchor-id="resultados">4. Resultados</h3>
<p>Lo primero a observar es la curva de aprendizaje, que no es tan bonita</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 9.png" class="img-fluid figure-img"></p>
<figcaption>Learning Curve GAN</figcaption>
</figure>
</div>
<p>Podemos ver lo inestable que es el entrenamiento, aunque si tiende a minimizar ambas funciones. Ahora vemos que im√°genes genera:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 10.png" class="img-fluid figure-img"></p>
<figcaption>Sample Results</figcaption>
</figure>
</div>
<p>Fuaaa ü§©&nbsp;Parecer ser que el modelo intenta converger y genera algunas im√°genes que si podrian enga√±ar al ojo humano.</p>
<p>Si te lo est√°s preguntando, la evaluaci√≥n real propuesta en el paper no es simple, en el paper utilizan unas t√©cnicas espec√≠ficas, pero para dejarlo simple, ac√° simplemente evaluaremos con la vista!</p>
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 11.png" class="img-fluid"></p>
<p>Algo importante es que idealmente en generaci√≥n de im√°genes no se aprenda de memoria las caracter√≠sticas de el conjunto de entrenamiento, si no que le agregue un poco de su saz√≥n! e.g al generar caras, en donde el set de entrenamiento no tienen ninguna cara con barba, nos gustar√≠a que pudiese generar caras con barba (esto es una limitante)</p>
<p>Veamos como va evolucionando el modelo cada 1000 iteraciones!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 12.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 0</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 13.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 2000</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 14.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 1000</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 15.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 3000</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 16.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 4000</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 17.png" class="img-fluid figure-img"></p>
<figcaption>Iteraci√≥n 15000</figcaption>
</figure>
</div>
<p>Observamos que ya a partir de la iteraci√≥n 4000 logra hacer un ‚Äú6‚Äù bastante decente.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>üìù
</div>
</div>
<div class="callout-body-container callout-body">
<p>PD: Mis disculpas por no haber hecho un plot m√°s ordenado ac√°!</p>
</div>
</div>
</section>
</section>
</section>
<section id="dcgan" class="level1">
<h1>DCGAN</h1>
<p>Mientras construiamos esto, nos pregunt√°bamos si podiamos utilizar CNNs en vez de MLPs. En el Paper <strong><a href="https://arxiv.org/abs/1511.06434">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a> lo hacen!</strong></p>
<p>Me encantar√≠a incluir la explicaci√≥n de como implement√© este paper tambi√©n (me gust√≥ m√°s porque incluyen todos los detalles de arquitectura), pero se est√° alargando mucho el post üò¢. Lo dejar√© para un futuro, a√∫n as√≠ puedes ver el c√≥digo y notebook en el Github. Para no dejarte con las ganas, te dejar√© con los resultados obtenidos, los cuales no son tan mejores en cu√°nto al dataset MNIST, pareciera que son predicciones m√°s suaves, pero debo mencionar que ac√° utilic√© un <code>img_size</code> de 64x64</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 18.png" class="img-fluid figure-img"></p>
<figcaption>MNIST Generations By DCGAN</figcaption>
</figure>
</div>
<p>Me gustan m√°s las generaciones hechas por GAN tradicional (Vanilla). Quiz√° pude haber mejorado m√°s el modelo, o haber iterado por m√°s tiempo. A√∫n as√≠, creo que la ventaja de DCGAN es que permite generar tipos de im√°genes m√°s complejas. Dicho esto, prob√© con el dataset CELEB, que son im√°genes de celebridades y estos fueron los resultados:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GAN Paper Implementation 52ba99d208bf45dfb1a22f2077ec3f77/Untitled 19.png" class="img-fluid figure-img"></p>
<figcaption>CELEB Generations by DCGAN</figcaption>
</figure>
</div>
<p>Yo veo que es un buen intento! Pude haber seguido iterando para encontrar mejores resultados, pero creo que por ahora es bastante decente! (Y me qued√© sin unidades de c√≥mputo üí∏üí∏üí∏)</p>
<p>Los GANs posteriores crean im√°genes bastantes m√°s realistas! Y para que hablar de los modelos de difusi√≥n y los avances que se han hecho hasta la fecha. ü§Øü§Øü§Øü§Ø</p>
</section>
<section id="conclusiones" class="level1">
<h1>Conclusiones</h1>
<p>La implementaci√≥n del paper sobre Adversarial Neural Networks (GAN) ha demostrado ser una herramienta poderosa para la generaci√≥n de datos realistas y la mejora de la calidad en diversas aplicaciones. La capacidad de generar contenido nuevo y convincente a trav√©s de la competencia entre el generador y el discriminador abre un mundo de posibilidades creativas. A medida que continuamos explorando y refinando estas t√©cnicas, podemos anticipar avances significativos en campos como la visi√≥n por computadora, el dise√±o de im√°genes y la generaci√≥n de contenido multimedia. ¬°El futuro de las GAN promete emocionantes desarrollos en la generaci√≥n de contenido artificial!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/diegulio\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>diegulioüß°2025</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>