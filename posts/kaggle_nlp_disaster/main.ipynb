{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88c0b6dd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Identificando desastres en Twitter con NLP\"\n",
    "image: \"disaster.jpeg\"\n",
    "sidebar:\n",
    "    contents:\n",
    "      - section: \"First Section\"\n",
    "        contents:\n",
    "          - href: seqclass-1-simple-nn.ipynb\n",
    "author: \"Diegulio\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "categories: [NLP, code, Kaggle]\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eb664ed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007079,
     "end_time": "2022-12-11T15:20:50.601635",
     "exception": false,
     "start_time": "2022-12-11T15:20:50.594556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Goal \n",
    "\n",
    "I'm learning NLP. So to do that I decided pass trough diverse NLP models, study the teory and code them! \n",
    "I think that it is a good method to learn Machine Learning things. So, Disclaimer: All the content on the notebooks is what I understood from diverse references (I will put the links), somethings could be wrong, If you find any mistake please let me know, so I can learn of it. Also, if you have some doubt, it will be a pleasure to me to answer it (as long as I have the answer).\n",
    "\n",
    "At the end, I achieve a score of 0.843 in the LB. Is beatifull to see how you are improving the solutions step by step!\n",
    "\n",
    "So, this will be the embedding Notebook, I will put the link to each specific notebook here (So it will be more readable).\n",
    "\n",
    "Methodologies & Notebooks:\n",
    "\n",
    "\n",
    "|           Model Notebook          | Score |\n",
    "|:-------------------------:|:-----:|\n",
    "| [Simple Neural Network](seqclass-1-simple-nn.html) ( [View on kaggle](https://www.kaggle.com/code/diegomachado/seqclass-1-simple-nn-0-56))    | 0.56  |\n",
    "| [Embeddings](seqclass-2-embeddings.html) ( [View on kaggle](https://www.kaggle.com/code/diegomachado/seqclass-2-embeddings-0-797))                | 0.797 |\n",
    "| [Recurrent Neural Networks](seqclass-3-rnn.html) ( [View on kaggle](https://www.kaggle.com/code/diegomachado/seqclass-3-rnn-0-809/notebook)) | 0.809 |\n",
    "| [BERT & HuggingFace](seqclass-4-bert-tensorflow-huggingface.html) ( [View on kaggle](https://www.kaggle.com/code/diegomachado/seqclass-4-bert-tensorflow-huggingface-0-824/notebook))        | 0.824 |\n",
    "| [MyBestSolution](seqclass-5-mybestsolution.html) ( [View on kaggle](https://www.kaggle.com/code/diegomachado/seqclass-5-mybestsolution-0-843/notebook))            | 0.843 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c536cb",
   "metadata": {
    "papermill": {
     "duration": 0.005523,
     "end_time": "2022-12-11T15:20:50.613166",
     "exception": false,
     "start_time": "2022-12-11T15:20:50.607643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA \n",
    "Here I will do some preprocessing and split the data. I will use that data to each notebook!\n",
    "\n",
    "I think there is a lot of notebooks with a beatifull EDA, So I won't take to much around this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29d2c3",
   "metadata": {
    "papermill": {
     "duration": 0.005521,
     "end_time": "2022-12-11T15:20:50.624641",
     "exception": false,
     "start_time": "2022-12-11T15:20:50.619120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f481bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:50.638441Z",
     "iopub.status.busy": "2022-12-11T15:20:50.637987Z",
     "iopub.status.idle": "2022-12-11T15:20:58.241569Z",
     "shell.execute_reply": "2022-12-11T15:20:58.240237Z"
    },
    "papermill": {
     "duration": 7.614549,
     "end_time": "2022-12-11T15:20:58.245025",
     "exception": false,
     "start_time": "2022-12-11T15:20:50.630476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization, Lambda\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "#import tensorflow_hub as hub\n",
    "#import tensorflow_text as text # Bert preprocess uses this \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51d832",
   "metadata": {
    "papermill": {
     "duration": 0.00565,
     "end_time": "2022-12-11T15:20:58.257137",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.251487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8d734f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.272035Z",
     "iopub.status.busy": "2022-12-11T15:20:58.270594Z",
     "iopub.status.idle": "2022-12-11T15:20:58.335245Z",
     "shell.execute_reply": "2022-12-11T15:20:58.334372Z"
    },
    "papermill": {
     "duration": 0.074284,
     "end_time": "2022-12-11T15:20:58.337395",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.263111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e65f121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.351641Z",
     "iopub.status.busy": "2022-12-11T15:20:58.351200Z",
     "iopub.status.idle": "2022-12-11T15:20:58.382734Z",
     "shell.execute_reply": "2022-12-11T15:20:58.381285Z"
    },
    "papermill": {
     "duration": 0.04157,
     "end_time": "2022-12-11T15:20:58.385241",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.343671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365ace5",
   "metadata": {
    "papermill": {
     "duration": 0.006216,
     "end_time": "2022-12-11T15:20:58.398228",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.392012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48285942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.414760Z",
     "iopub.status.busy": "2022-12-11T15:20:58.413961Z",
     "iopub.status.idle": "2022-12-11T15:20:58.572294Z",
     "shell.execute_reply": "2022-12-11T15:20:58.571074Z"
    },
    "papermill": {
     "duration": 0.168582,
     "end_time": "2022-12-11T15:20:58.574824",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.406242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target Proportion\n",
    "sns.countplot(data=train_df, x = \"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bdfe4",
   "metadata": {
    "papermill": {
     "duration": 0.006429,
     "end_time": "2022-12-11T15:20:58.588018",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.581589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I think it is balanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1bebc86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.603625Z",
     "iopub.status.busy": "2022-12-11T15:20:58.602820Z",
     "iopub.status.idle": "2022-12-11T15:20:58.612426Z",
     "shell.execute_reply": "2022-12-11T15:20:58.611216Z"
    },
    "papermill": {
     "duration": 0.020436,
     "end_time": "2022-12-11T15:20:58.615082",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.594646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'California Bush fires please evacuate affected areas ASAP when california govts advised you to do so http://t.co/ubVEVUuAch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random example of disaster tweet\n",
    "train_df[train_df.target == 1].sample(1).text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3016e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.630316Z",
     "iopub.status.busy": "2022-12-11T15:20:58.629908Z",
     "iopub.status.idle": "2022-12-11T15:20:58.638980Z",
     "shell.execute_reply": "2022-12-11T15:20:58.638047Z"
    },
    "papermill": {
     "duration": 0.019395,
     "end_time": "2022-12-11T15:20:58.641242",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.621847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Someone split a mudslide w me when I get off work'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random example of NO disaster tweet\n",
    "train_df[train_df.target == 0].sample(1).text.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150bde7",
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2022-12-11T15:20:58.654809",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.648198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pre-processing\n",
    "\n",
    "I will do some preprocessing with Tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709983a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.670795Z",
     "iopub.status.busy": "2022-12-11T15:20:58.670342Z",
     "iopub.status.idle": "2022-12-11T15:20:58.717313Z",
     "shell.execute_reply": "2022-12-11T15:20:58.716425Z"
    },
    "papermill": {
     "duration": 0.05762,
     "end_time": "2022-12-11T15:20:58.719376",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.661756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:20:58.687517: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Tensor Data\n",
    "text = tf.data.Dataset.from_tensor_slices(train_df.text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a83b7d",
   "metadata": {
    "papermill": {
     "duration": 0.006721,
     "end_time": "2022-12-11T15:20:58.733489",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.726768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that Im reading data from memory! If it would huge data I would be in troubles! \n",
    "\n",
    "One advantage of initialize a Tensorflow dataset is that I will be able to create a data pipeline (batch, fetch, shuffle, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611b8a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.749790Z",
     "iopub.status.busy": "2022-12-11T15:20:58.748929Z",
     "iopub.status.idle": "2022-12-11T15:20:58.789902Z",
     "shell.execute_reply": "2022-12-11T15:20:58.788978Z"
    },
    "papermill": {
     "duration": 0.051817,
     "end_time": "2022-12-11T15:20:58.792416",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.740599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
       " b'Forest fire near La Ronge Sask. Canada']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some samples\n",
    "list(text.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28cf432",
   "metadata": {
    "papermill": {
     "duration": 0.006978,
     "end_time": "2022-12-11T15:20:58.806544",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.799566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to know that models don't understand text by itself! Just numbers! For this, we vectorize the sentences. I don't plan to use a model now, I would like to observe wich words are more present by target! (Also I don't want to consider **stopwords**) \n",
    "\n",
    "I will use the tensorflow layer: Text Vectorization. from behind, it apply lowercase and delete punctuation. I also wants to remove stopwords, so I will build a custom standarization that do: \n",
    "1. lowercase\n",
    "2. strip punctuation\n",
    "3. remove stop words! \n",
    "\n",
    "[Click here if you don't know what are stop words](https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3c9649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:20:58.822997Z",
     "iopub.status.busy": "2022-12-11T15:20:58.822181Z",
     "iopub.status.idle": "2022-12-11T15:21:06.971847Z",
     "shell.execute_reply": "2022-12-11T15:21:06.970305Z"
    },
    "papermill": {
     "duration": 8.161047,
     "end_time": "2022-12-11T15:21:06.974712",
     "exception": false,
     "start_time": "2022-12-11T15:20:58.813665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:20:58.997911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disaster_target</th>\n",
       "      <th>variable</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>im</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>amp</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>new</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>fire</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>get</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>dont</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>news</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>via</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>body</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>california</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>suicide</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>people</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>police</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>disaster</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>via</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>amp</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>killed</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>video</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>like</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>hiroshima</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>fires</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>know</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>full</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>love</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>time</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     disaster_target    variable  count\n",
       "2                  0        like  239.0\n",
       "4                  0          im  221.0\n",
       "6                  0         amp  174.0\n",
       "12                 0         new  163.0\n",
       "9                  1        fire  162.0\n",
       "10                 0         get  158.0\n",
       "22                 0        dont  136.0\n",
       "21                 1        news  130.0\n",
       "18                 0         one  122.0\n",
       "15                 1         via  121.0\n",
       "42                 0        body  110.0\n",
       "51                 1  california  108.0\n",
       "53                 1     suicide  104.0\n",
       "17                 1      people  101.0\n",
       "37                 1      police   97.0\n",
       "35                 1    disaster   96.0\n",
       "14                 0         via   96.0\n",
       "7                  1         amp   95.0\n",
       "38                 0       would   93.0\n",
       "95                 1      killed   90.0\n",
       "24                 0       video   90.0\n",
       "16                 0      people   90.0\n",
       "3                  1        like   88.0\n",
       "117                1   hiroshima   84.0\n",
       "87                 1       fires   82.0\n",
       "62                 0        know   82.0\n",
       "28                 0           2   81.0\n",
       "104                0        full   81.0\n",
       "84                 0        love   81.0\n",
       "58                 0        time   80.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### COUNT WORDS BY TARGET\n",
    "\n",
    "def custom_standardization(inputs):\n",
    "    \"\"\"\n",
    "    Apply: lowercase, remove punctuation and stopwords\n",
    "    \"\"\"\n",
    "    PUNCTUATION = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n",
    "    lowercase = tf.strings.lower(inputs) # lowercase\n",
    "    strip = tf.strings.regex_replace(lowercase, PUNCTUATION, '') # strip punctuation\n",
    "    stopwrd = tf.strings.regex_replace(strip, r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*', '')\n",
    "    return stopwrd\n",
    "    \n",
    "\n",
    "# model to apply vectorize_layer with custom standardization\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(output_mode = 'multi_hot', standardize = custom_standardization)\n",
    "vectorize_layer.adapt(text)\n",
    "\n",
    "# model to vectorize\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# make counter\n",
    "train_count = model.predict(text.batch(batch_size = len(text))) # predict to count \n",
    "token_counts = pd.DataFrame(columns = vectorize_layer.get_vocabulary(), data = train_count) # df with tokens and count\n",
    "train_df.rename(columns = {\"target\":\"disaster_target\"}, inplace = True) # rename target because there is a word target in data\n",
    "count_df = pd.concat([train_df, token_counts], axis = 1) #concat\n",
    "group_count = count_df.iloc[:,4:].groupby(\"disaster_target\", as_index = False).sum() # count token for each target\n",
    "melt_count = pd.melt(group_count, id_vars=[\"disaster_target\"], value_name = \"count\") # each token to row\n",
    "melt_count.sort_values(by=[\"count\"], ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e70ef",
   "metadata": {
    "papermill": {
     "duration": 0.007443,
     "end_time": "2022-12-11T15:21:06.990406",
     "exception": false,
     "start_time": "2022-12-11T15:21:06.982963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After I build it I realized that it is not necessary to instantiate a model to use layers! 😅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd45f2",
   "metadata": {
    "papermill": {
     "duration": 0.007273,
     "end_time": "2022-12-11T15:21:07.005315",
     "exception": false,
     "start_time": "2022-12-11T15:21:06.998042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00da2601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:21:07.022834Z",
     "iopub.status.busy": "2022-12-11T15:21:07.022033Z",
     "iopub.status.idle": "2022-12-11T15:21:07.026541Z",
     "shell.execute_reply": "2022-12-11T15:21:07.025770Z"
    },
    "papermill": {
     "duration": 0.015621,
     "end_time": "2022-12-11T15:21:07.028614",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.012993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c33dd13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:21:07.045877Z",
     "iopub.status.busy": "2022-12-11T15:21:07.045443Z",
     "iopub.status.idle": "2022-12-11T15:21:07.055778Z",
     "shell.execute_reply": "2022-12-11T15:21:07.054675Z"
    },
    "papermill": {
     "duration": 0.02154,
     "end_time": "2022-12-11T15:21:07.058053",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.036513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[[col for col in train_df.columns if col != 'disaster_target']], train_df.disaster_target, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6edc2a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:21:07.075236Z",
     "iopub.status.busy": "2022-12-11T15:21:07.074838Z",
     "iopub.status.idle": "2022-12-11T15:21:07.118504Z",
     "shell.execute_reply": "2022-12-11T15:21:07.116979Z"
    },
    "papermill": {
     "duration": 0.055574,
     "end_time": "2022-12-11T15:21:07.121569",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.065995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To csv (In some notebooks I will use this data)\n",
    "pd.concat([X_train, y_train], axis = 1).to_csv('df_train.csv',index = False)\n",
    "pd.concat([X_test, y_test], axis = 1).to_csv('df_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24bff5",
   "metadata": {
    "papermill": {
     "duration": 0.007861,
     "end_time": "2022-12-11T15:21:07.137420",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.129559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This dataset is here: https://www.kaggle.com/datasets/diegomachado/df-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f9bc6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:21:07.155372Z",
     "iopub.status.busy": "2022-12-11T15:21:07.154981Z",
     "iopub.status.idle": "2022-12-11T15:21:07.351155Z",
     "shell.execute_reply": "2022-12-11T15:21:07.350035Z"
    },
    "papermill": {
     "duration": 0.207855,
     "end_time": "2022-12-11T15:21:07.353525",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.145670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete it from memory\n",
    "del train_df, test_df, X_train, X_test, y_train, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8768e9",
   "metadata": {
    "papermill": {
     "duration": 0.007921,
     "end_time": "2022-12-11T15:21:07.369486",
     "exception": false,
     "start_time": "2022-12-11T15:21:07.361565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.156484,
   "end_time": "2022-12-11T15:21:10.520500",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-11T15:20:42.364016",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
